{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 08:40:19.304129: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Regression\n",
    "It is now time to implements single-input and multiple-inputs DNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Initializing DNN program\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Importing Libraries\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oarreche@ads.iu.edu/anaconda3/envs/tf23/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining Metric Equations\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Defining features of interest\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Loading Databases\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Normalizing database\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Separating features and labels\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Counter({'BENIGN': 756652, 'Dos/Ddos': 127047, 'PortScan': 52987, 'Brute Force': 4594, 'Web Attack': 716, 'Bot': 628, 'Infiltration': 13})\n",
      "---------------------------------------------------------------------------------\n",
      "Counter({'BENIGN': 756652, 'Dos/Ddos': 127047, 'PortScan': 52987, 'Brute Force': 4594, 'Web Attack': 716, 'Bot': 628, 'Infiltration': 13})\n",
      "---------------------------------------------------------------------------------\n",
      "Separating Training and Testing db\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------')\n",
    "print('Initializing DNN program')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "#---------------------------------------------------------------------\n",
    "# Importing Libraries\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Importing Libraries')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import LSTM\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.preprocessing import sequence\n",
    "#from keras.utils import pad_sequences\n",
    "#from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import shap\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.random.seed(0)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Defining metric equations\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining Metric Equations')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "def ACC(TP,TN,FP,FN):\n",
    "    Acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return Acc\n",
    "def ACC_2 (TP, FN):\n",
    "    ac = (TP/(TP+FN))\n",
    "    return ac\n",
    "def PRECISION(TP,FP):\n",
    "    Precision = TP/(TP+FP)\n",
    "    return Precision\n",
    "def RECALL(TP,FN):\n",
    "    Recall = TP/(TP+FN)\n",
    "    return Recall\n",
    "def F1(Recall, Precision):\n",
    "    F1 = 2 * Recall * Precision / (Recall + Precision)\n",
    "    return F1\n",
    "def BACC(TP,TN,FP,FN):\n",
    "    BACC =(TP/(TP+FN)+ TN/(TN+FP))*0.5\n",
    "    return BACC\n",
    "def MCC(TP,TN,FP,FN):\n",
    "    MCC = (TN*TP-FN*FP)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**.5)\n",
    "    return MCC\n",
    "def AUC_ROC(y_test_bin,y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    auc_avg = 0\n",
    "    counting = 0\n",
    "    for i in range(n_classes):\n",
    "      fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "     # plt.plot(fpr[i], tpr[i], color='darkorange', lw=2)\n",
    "      #print('AUC for Class {}: {}'.format(i+1, auc(fpr[i], tpr[i])))\n",
    "      auc_avg += auc(fpr[i], tpr[i])\n",
    "      counting = i+1\n",
    "    return auc_avg/counting\n",
    "#---------------------------------------------------------------------\n",
    "# Defining features of interest\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining features of interest')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "# req_cols = [ ' Packet Length Std', ' Total Length of Bwd Packets', ' Subflow Bwd Bytes',\n",
    "# ' Destination Port', ' Packet Length Variance', ' Bwd Packet Length Mean',' Avg Bwd Segment Size',\n",
    "# 'Bwd Packet Length Max', ' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
    "# ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' Average Packet Size', ' Packet Length Mean',\n",
    "# ' Max Packet Length',' Label']\n",
    "\n",
    "# req_cols = [' Destination Port',' Flow Duration',' Total Fwd Packets',' Total Backward Packets','Total Length of Fwd Packets',' Total Length of Bwd Packets',' Fwd Packet Length Max',' Fwd Packet Length Min',' Fwd Packet Length Mean',' Fwd Packet Length Std','Bwd Packet Length Max',' Bwd Packet Length Min',' Bwd Packet Length Mean',' Bwd Packet Length Std','Flow Bytes/s',' Flow Packets/s',' Flow IAT Mean',' Flow IAT Std',' Flow IAT Max',' Flow IAT Min','Fwd IAT Total',' Fwd IAT Mean',' Fwd IAT Std',' Fwd IAT Max',' Fwd IAT Min','Bwd IAT Total',' Bwd IAT Mean',' Bwd IAT Std',' Bwd IAT Max',' Bwd IAT Min','Fwd PSH Flags',' Bwd PSH Flags',' Fwd URG Flags',' Bwd URG Flags',' Fwd Header Length',' Bwd Header Length','Fwd Packets/s',' Bwd Packets/s',' Min Packet Length',' Max Packet Length',' Packet Length Mean',' Packet Length Std',' Packet Length Variance','FIN Flag Count',' SYN Flag Count',' RST Flag Count',' PSH Flag Count',' ACK Flag Count',' URG Flag Count',' CWE Flag Count',' ECE Flag Count',' Down/Up Ratio',' Average Packet Size',' Avg Fwd Segment Size',' Avg Bwd Segment Size',' Fwd Header Length','Fwd Avg Bytes/Bulk',' Fwd Avg Packets/Bulk',' Fwd Avg Bulk Rate',' Bwd Avg Bytes/Bulk',' Bwd Avg Packets/Bulk','Bwd Avg Bulk Rate','Subflow Fwd Packets',' Subflow Fwd Bytes',' Subflow Bwd Packets',' Subflow Bwd Bytes','Init_Win_bytes_forward',' Init_Win_bytes_backward',' act_data_pkt_fwd',' min_seg_size_forward','Active Mean',' Active Std',' Active Max',' Active Min','Idle Mean',' Idle Std',' Idle Max',' Idle Min',' Label']\n",
    "\n",
    "# req_cols = [' Down/Up Ratio', ' Fwd URG Flags', ' Flow IAT Std', 'Subflow Fwd Packets', ' Flow Packets/s', ' URG Flag Count', 'FIN Flag Count', ' Bwd Packets/s', 'Bwd Avg Bulk Rate', ' act_data_pkt_fwd', ' Fwd Packet Length Std', ' Bwd Avg Bytes/Bulk', ' Active Max', ' Flow IAT Max', ' min_seg_size_forward', ' Bwd Packet Length Std', ' Fwd IAT Std', ' Fwd Avg Bulk Rate', ' Fwd Packet Length Mean', ' Fwd Packet Length Max', ' Idle Std', ' CWE Flag Count', 'Fwd IAT Total', ' ACK Flag Count', ' Bwd URG Flags', ' Flow IAT Min', ' Flow IAT Mean', ' Total Backward Packets', ' Fwd Avg Packets/Bulk', 'Fwd Avg Bytes/Bulk', ' SYN Flag Count', ' Min Packet Length', ' Fwd Packet Length Min', 'Idle Mean', 'Fwd PSH Flags', ' Fwd IAT Min', ' Fwd Header Length', ' RST Flag Count', ' Idle Max', ' PSH Flag Count', ' Bwd Header Length', ' ECE Flag Count', ' Subflow Bwd Packets', 'Active Mean', 'Flow Bytes/s', ' Bwd IAT Mean', ' Avg Fwd Segment Size', ' Bwd Packet Length Min', ' Active Std', ' Bwd IAT Min', ' Flow Duration', 'Fwd Packets/s', ' Fwd IAT Max', 'Bwd IAT Total', ' Idle Min', ' Bwd PSH Flags', ' Bwd Avg Packets/Bulk', ' Total Fwd Packets', ' Active Min', ' Bwd IAT Std', ' Fwd IAT Mean', ' Bwd IAT Max', ' Label']\n",
    "\n",
    "req_cols = [\n",
    "    \n",
    "    ' Packet Length Std', ' Total Length of Bwd Packets', ' Subflow Bwd Bytes',\n",
    "    ' Destination Port', ' Packet Length Variance', ' Bwd Packet Length Mean',' Avg Bwd Segment Size',\n",
    "    'Bwd Packet Length Max', ' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
    "    ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' Average Packet Size', ' Packet Length Mean',\n",
    "    ' Max Packet Length',\n",
    "    ' Down/Up Ratio', ' Fwd URG Flags', ' Flow IAT Std', 'Subflow Fwd Packets', ' Flow Packets/s', ' URG Flag Count', 'FIN Flag Count', ' Bwd Packets/s', 'Bwd Avg Bulk Rate'\n",
    "    , ' act_data_pkt_fwd', ' Fwd Packet Length Std', ' Bwd Avg Bytes/Bulk', ' Active Max', ' Flow IAT Max', ' min_seg_size_forward', ' Bwd Packet Length Std', ' Fwd IAT Std', ' Fwd Avg Bulk Rate', ' Fwd Packet Length Mean', ' Fwd Packet Length Max', ' Idle Std', ' CWE Flag Count', 'Fwd IAT Total'\n",
    "    \n",
    "    , ' ACK Flag Count', ' Bwd URG Flags', ' Flow IAT Min', ' Flow IAT Mean', ' Total Backward Packets', ' Fwd Avg Packets/Bulk', 'Fwd Avg Bytes/Bulk', ' SYN Flag Count', ' Min Packet Length', ' Fwd Packet Length Min', 'Idle Mean', 'Fwd PSH Flags', ' Fwd IAT Min'\n",
    "     \n",
    "    ,  ' Fwd Header Length', ' RST Flag Count', ' Idle Max', ' PSH Flag Count', ' Bwd Header Length', ' ECE Flag Count', ' Subflow Bwd Packets', 'Active Mean', 'Flow Bytes/s', ' Bwd IAT Mean', ' Avg Fwd Segment Size', ' Bwd Packet Length Min', ' Active Std', ' Bwd IAT Min', ' Flow Duration', 'Fwd Packets/s', ' Fwd IAT Max', 'Bwd IAT Total', ' Idle Min', ' Bwd PSH Flags', ' Bwd Avg Packets/Bulk', ' Total Fwd Packets', ' Active Min', ' Bwd IAT Std', ' Fwd IAT Mean', ' Bwd IAT Max'\n",
    "            \n",
    "            , ' Label']\n",
    "\n",
    "# Information gain top 10 features\n",
    "top10 = [' Average Packet Size',\n",
    "          ' Packet Length Std', \n",
    "          ' Packet Length Variance', \n",
    "          ' Packet Length Mean',\n",
    "            ' Destination Port', \n",
    "            ' Subflow Bwd Bytes', \n",
    "            ' Total Length of Bwd Packets', \n",
    "            ' Avg Bwd Segment Size', \n",
    "            ' Bwd Packet Length Mean',  \n",
    "            'Bwd Packet Length Max', \n",
    "            ' Label']\n",
    "\n",
    "\n",
    "\n",
    "# req_cols = top10\n",
    "\n",
    "# req_cols = [' Destination Port',' Flow Duration',' Total Fwd Packets',' Total Backward Packets','Total Length of Fwd Packets',' Total Length of Bwd Packets',' Label']\n",
    "#---------------------------------------------------------------------\n",
    "#Load Databases from csv file\n",
    "\n",
    "path_str = '/home/oarreche@ads.iu.edu/HITL/cicids/cicids_db/'\n",
    "fraction = 1\n",
    "#---------------------------------------------------------------------\n",
    "#Load Databases from csv file\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Loading Databases')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "\n",
    "df0 = pd.read_csv (path_str + 'Wednesday-workingHours.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "df1 = pd.read_csv (path_str + 'Tuesday-WorkingHours.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv (path_str +'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df3 = pd.read_csv (path_str +'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df4 = pd.read_csv (path_str +'Monday-WorkingHours.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df5 = pd.read_csv (path_str +'Friday-WorkingHours-Morning.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df6 = pd.read_csv (path_str +'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df7 = pd.read_csv (path_str +'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "frames = [df0, df1, df2, df3, df4, df5, df6, df7]\n",
    "\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "df = df.sample(frac = 0.333)\n",
    "\n",
    "\n",
    "\n",
    "# IG popping unwandted columns descriptive accuracy\n",
    "\n",
    "# df.pop(' min_seg_size_forward')\n",
    "# df.pop(' PSH Flag Count')\n",
    "# df.pop(' ACK Flag Count')\n",
    "# df.pop('Init_Win_bytes_forward')\n",
    "# df.pop(' Destination Port')\n",
    "\n",
    "# df.pop(' Bwd Packet Length Mean')\n",
    "# df.pop('Fwd Packets/s')\n",
    "# df.pop(' Init_Win_bytes_backward')\n",
    "# df.pop(' Packet Length Mean')\n",
    "# df.pop(' Packet Length Std')\n",
    "\n",
    "# df.pop(' Bwd Packet Length Std')\n",
    "# df.pop(' Avg Bwd Segment Size')\n",
    "# df.pop(' Packet Length Variance')\n",
    "# df.pop(' Flow Duration')\n",
    "# df.pop(' Max Packet Length')\n",
    "# df.pop(' Flow IAT Max')\n",
    "# df.pop(' Idle Max')\n",
    "# df.pop('Bwd Packet Length Max')\n",
    "# df.pop(' Fwd IAT Max')\n",
    "# df.pop(' URG Flag Count')\n",
    "# df.pop('Fwd PSH Flags')\n",
    "\n",
    "# df.pop(' Min Packet Length')\n",
    "# df.pop('Idle Mean')\n",
    "# df.pop(' Fwd Packet Length Min')\n",
    "# df.pop(' Average Packet Size')\n",
    "# df.pop(' Idle Min')\n",
    "# df.pop('Bwd IAT Total')\n",
    "# df.pop('Fwd IAT Total')\n",
    "# df.pop(' Fwd Packet Length Max')\n",
    "# df.pop(' Avg Fwd Segment Size')\n",
    "# df.pop(' SYN Flag Count')\n",
    "# df.pop(' Fwd Packet Length Mean')\n",
    "# df.pop(' Flow IAT Std')\n",
    "# df.pop(' Down/Up Ratio')\n",
    "# df.pop(' Fwd IAT Mean')\n",
    "# df.pop('FIN Flag Count')\n",
    "# df.pop(' Bwd Packets/s')\n",
    "# df.pop(' Fwd Packet Length Std')\n",
    "# df.pop(' Flow IAT Mean')\n",
    "# df.pop(' Bwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Std')\n",
    "# df.pop(' Bwd IAT Mean')\n",
    "\n",
    "# df.pop(' Bwd IAT Std')\n",
    "# df.pop(' Bwd IAT Max')\n",
    "# df.pop(' Bwd IAT Min')\n",
    "# df.pop(' Fwd IAT Min')\n",
    "# df.pop(' Idle Std')\n",
    "# df.pop(' Active Max')\n",
    "# df.pop(' RST Flag Count')\n",
    "# df.pop(' Subflow Fwd Bytes')\n",
    "# df.pop(' ECE Flag Count')\n",
    "# df.pop(' Flow IAT Min')\n",
    "# df.pop('Total Length of Fwd Packets')\n",
    "# df.pop(' Active Std')\n",
    "# df.pop(' Active Min')\n",
    "# df.pop(' Bwd Header Length')\n",
    "# df.pop(' Fwd Header Length')\n",
    "# df.pop('Active Mean')\n",
    "# df.pop(' Total Fwd Packets')\n",
    "# df.pop(' Total Backward Packets')\n",
    "# df.pop('Subflow Fwd Packets')\n",
    "# df.pop(' act_data_pkt_fwd')\n",
    "# df.pop(' Subflow Bwd Bytes')\n",
    "# df.pop(' Fwd URG Flags')\n",
    "# df.pop(' CWE Flag Count')\n",
    "# df.pop(' Subflow Bwd Packets')\n",
    "# df.pop(' Total Length of Bwd Packets')\n",
    "# df.pop('Flow Bytes/s')\n",
    "# df.pop(' Flow Packets/s')\n",
    "# df.pop(' Bwd PSH Flags')\n",
    "# df.pop(' Bwd URG Flags')\n",
    "# df.pop('Fwd Avg Bytes/Bulk')\n",
    "# df.pop(' Fwd Avg Packets/Bulk')\n",
    "# df.pop(' Fwd Avg Bulk Rate')\n",
    "# df.pop(' Bwd Avg Bytes/Bulk')\n",
    "# df.pop(' Bwd Avg Packets/Bulk')\n",
    "# df.pop('Bwd Avg Bulk Rate')\n",
    "\n",
    "# LRP popping unwandted columns descriptive accuracy\n",
    "\n",
    "\n",
    "# df.pop(' min_seg_size_forward')\n",
    "# df.pop(' PSH Flag Count')\n",
    "# df.pop(' ACK Flag Count')\n",
    "# df.pop('Init_Win_bytes_forward')\n",
    "# df.pop(' Destination Port')\n",
    "\n",
    "# df.pop(' Bwd Packet Length Mean')\n",
    "# df.pop('Fwd Packets/s')\n",
    "# df.pop(' Init_Win_bytes_backward')\n",
    "# df.pop(' Packet Length Mean')\n",
    "# df.pop(' Packet Length Std')\n",
    "\n",
    "# df.pop(' Bwd Packet Length Std')\n",
    "# df.pop(' Avg Bwd Segment Size')\n",
    "# df.pop(' Packet Length Variance')\n",
    "# df.pop(' Flow Duration')\n",
    "# df.pop(' Max Packet Length')\n",
    "# df.pop(' Flow IAT Max')\n",
    "# df.pop(' Idle Max')\n",
    "# df.pop('Bwd Packet Length Max')\n",
    "# df.pop(' Fwd IAT Max')\n",
    "# df.pop(' URG Flag Count')\n",
    "# df.pop('Fwd PSH Flags')\n",
    "\n",
    "# df.pop(' Min Packet Length')\n",
    "# df.pop('Idle Mean')\n",
    "# df.pop(' Fwd Packet Length Min')\n",
    "# df.pop(' Average Packet Size')\n",
    "# df.pop(' Idle Min')\n",
    "# df.pop('Bwd IAT Total')\n",
    "# df.pop('Fwd IAT Total')\n",
    "# df.pop(' Fwd Packet Length Max')\n",
    "# df.pop(' Avg Fwd Segment Size')\n",
    "# df.pop(' SYN Flag Count')\n",
    "# df.pop(' Fwd Packet Length Mean')\n",
    "# df.pop(' Flow IAT Std')\n",
    "# df.pop(' Down/Up Ratio')\n",
    "# df.pop(' Fwd IAT Mean')\n",
    "# df.pop('FIN Flag Count')\n",
    "# df.pop(' Bwd Packets/s')\n",
    "# df.pop(' Fwd Packet Length Std')\n",
    "# df.pop(' Flow IAT Mean')\n",
    "# df.pop(' Bwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Std')\n",
    "# df.pop(' Bwd IAT Mean')\n",
    "# df.pop(' Bwd IAT Std')\n",
    "\n",
    "# df.pop(' Bwd IAT Max')\n",
    "# df.pop(' Bwd IAT Min')\n",
    "# df.pop(' Fwd IAT Min')\n",
    "# df.pop(' Idle Std')\n",
    "# df.pop(' Active Max')\n",
    "# df.pop(' RST Flag Count')\n",
    "# df.pop(' Subflow Fwd Bytes')\n",
    "# df.pop(' ECE Flag Count')\n",
    "# df.pop(' Flow IAT Min')\n",
    "# df.pop('Total Length of Fwd Packets')\n",
    "# df.pop(' Active Std')\n",
    "# df.pop(' Active Min')\n",
    "# df.pop(' Bwd Header Length')\n",
    "# df.pop(' Fwd Header Length')\n",
    "# df.pop('Active Mean')\n",
    "# df.pop(' Total Fwd Packets')\n",
    "# df.pop(' Total Backward Packets')\n",
    "# df.pop('Subflow Fwd Packets')\n",
    "# df.pop(' act_data_pkt_fwd')\n",
    "# df.pop(' Subflow Bwd Bytes')\n",
    "# df.pop(' Fwd URG Flags')\n",
    "# df.pop(' CWE Flag Count')\n",
    "# df.pop(' Subflow Bwd Packets')\n",
    "# df.pop(' Total Length of Bwd Packets')\n",
    "# df.pop('Flow Bytes/s')\n",
    "# df.pop(' Flow Packets/s')\n",
    "# df.pop(' Bwd PSH Flags')\n",
    "# df.pop(' Bwd URG Flags')\n",
    "# df.pop('Fwd Avg Bytes/Bulk')\n",
    "# df.pop(' Fwd Avg Packets/Bulk')\n",
    "# df.pop(' Fwd Avg Bulk Rate')\n",
    "# df.pop(' Bwd Avg Bytes/Bulk')\n",
    "# df.pop(' Bwd Avg Packets/Bulk')\n",
    "# df.pop('Bwd Avg Bulk Rate')\n",
    "\n",
    "\n",
    "# DeepLift popping unwandted columns descriptive accuracy\n",
    "\n",
    "# df.pop(' PSH Flag Count')\n",
    "# df.pop(' ACK Flag Count')\n",
    "# df.pop(' Bwd Packet Length Mean')\n",
    "# df.pop('Init_Win_bytes_forward')\n",
    "# df.pop(' Bwd Packet Length Std')\n",
    "\n",
    "# df.pop('Fwd Packets/s')\n",
    "# df.pop(' Packet Length Std')\n",
    "# df.pop(' Packet Length Variance')\n",
    "# df.pop(' Destination Port')\n",
    "# df.pop(' Avg Bwd Segment Size')\n",
    "\n",
    "# df.pop(' Packet Length Mean')\n",
    "# df.pop(' URG Flag Count')\n",
    "# df.pop(' Idle Max')\n",
    "# df.pop(' Flow IAT Max')\n",
    "# df.pop('Fwd PSH Flags')\n",
    "# df.pop(' Flow Duration')\n",
    "# df.pop(' Max Packet Length')\n",
    "# df.pop('Bwd Packet Length Max')\n",
    "# df.pop(' Fwd IAT Max')\n",
    "# df.pop('FIN Flag Count')\n",
    "# df.pop(' min_seg_size_forward')\n",
    "\n",
    "# df.pop('Idle Mean')\n",
    "# df.pop(' Idle Min')\n",
    "# df.pop(' Init_Win_bytes_backward')\n",
    "# df.pop('Bwd IAT Total')\n",
    "# df.pop('Fwd IAT Total')\n",
    "# df.pop(' Average Packet Size')\n",
    "# df.pop(' Flow IAT Std')\n",
    "# df.pop(' Min Packet Length')\n",
    "# df.pop(' SYN Flag Count')\n",
    "# df.pop(' Fwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Mean')\n",
    "# df.pop(' Bwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Std')\n",
    "# df.pop(' Fwd Packet Length Max')\n",
    "# df.pop(' Fwd Packet Length Mean')\n",
    "# df.pop(' Fwd Packet Length Std')\n",
    "# df.pop(' Flow IAT Mean')\n",
    "# df.pop(' Avg Fwd Segment Size')\n",
    "# df.pop(' Bwd IAT Max')\n",
    "# df.pop(' Bwd IAT Mean')\n",
    "# df.pop(' Down/Up Ratio')\n",
    "\n",
    "# df.pop(' Bwd IAT Min')\n",
    "# df.pop(' Fwd IAT Min')\n",
    "# df.pop(' Bwd IAT Std')\n",
    "# df.pop(' Bwd Packets/s')\n",
    "# df.pop(' Idle Std')\n",
    "# df.pop(' Active Max')\n",
    "# df.pop(' Flow IAT Min')\n",
    "# df.pop(' Subflow Fwd Bytes')\n",
    "# df.pop('Total Length of Fwd Packets')\n",
    "# df.pop(' Active Std')\n",
    "# df.pop(' RST Flag Count')\n",
    "# df.pop(' Active Min')\n",
    "# df.pop('Active Mean')\n",
    "# df.pop(' ECE Flag Count')\n",
    "# df.pop(' CWE Flag Count')\n",
    "# df.pop(' Fwd URG Flags')\n",
    "# df.pop(' Total Backward Packets')\n",
    "# df.pop(' act_data_pkt_fwd')\n",
    "# df.pop(' Total Fwd Packets')\n",
    "# df.pop(' Subflow Bwd Bytes')\n",
    "# df.pop('Subflow Fwd Packets')\n",
    "# df.pop(' Fwd Header Length')\n",
    "# df.pop(' Bwd Header Length')\n",
    "# df.pop(' Subflow Bwd Packets')\n",
    "# df.pop(' Total Length of Bwd Packets')\n",
    "# df.pop('Bwd Avg Bulk Rate')\n",
    "# df.pop(' Bwd Avg Packets/Bulk')\n",
    "# df.pop(' Bwd Avg Bytes/Bulk')\n",
    "# df.pop(' Fwd Avg Bulk Rate')\n",
    "# df.pop(' Fwd Avg Packets/Bulk')\n",
    "# df.pop(' Bwd PSH Flags')\n",
    "# df.pop('Flow Bytes/s')\n",
    "# df.pop(' Flow Packets/s')\n",
    "# df.pop(' Bwd URG Flags')\n",
    "# df.pop('Fwd Avg Bytes/Bulk')\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Normalize database\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Normalizing database')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "df_max_scaled = df.copy()\n",
    "\n",
    "y = df_max_scaled[' Label'].replace({'DDoS' :'Dos/Ddos' ,'DoS GoldenEye': 'Dos/Ddos', 'DoS Hulk': 'Dos/Ddos', 'DoS Slowhttptest': 'Dos/Ddos', 'DoS slowloris': 'Dos/Ddos', 'Heartbleed': 'Dos/Ddos','FTP-Patator': 'Brute Force', 'SSH-Patator': 'Brute Force','Web Attack - Brute Force': 'Web Attack', 'Web Attack - Sql Injection': 'Web Attack', 'Web Attack - XSS': 'Web Attack'})\n",
    "\n",
    "df_max_scaled.pop(' Label')\n",
    "\n",
    "\n",
    "df_max_scaled\n",
    "for col in df_max_scaled.columns:\n",
    "    t = abs(df_max_scaled[col].max())\n",
    "    df_max_scaled[col] = df_max_scaled[col]/t\n",
    "df_max_scaled\n",
    "df = df_max_scaled.assign( Label = y)\n",
    "#df\n",
    "df = df.fillna(0)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# Separate features and labels \n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating features and labels')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "y = df.pop('Label')\n",
    "X = df\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "# transform the dataset\n",
    "# print('---------------------------------------------------------------------------------')\n",
    "# result_list = [counter['None'],counter['Denial of Service'], counter['Port Scanning']]\n",
    "# print('number of Labels  ',result_list)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# # Create an instance of RandomUnderSampler\n",
    "# rus = RandomUnderSampler()\n",
    "\n",
    "# # Balance the dataset using RandomUnderSampler\n",
    "# X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# # Create an instance of SMOTE\n",
    "# smote = SMOTE()\n",
    "\n",
    "# # Balance the dataset using SMOTE\n",
    "# X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# X = X_resampled\n",
    "# y = y_resampled\n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "df = X.assign( Label = y)\n",
    "\n",
    "y, label = pd.factorize(y)\n",
    "# y_test, label = pd.factorize(test['Label'])\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# Separate Training and Testing db\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating Training and Testing db')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.7,random_state=42)\n",
    "df = X.assign( Label = y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Now you can use Keras modules directly from tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Flatten\n",
    "import innvestigate\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining the DNN model\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining the DNN model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "# dropout_rate = 0.01\n",
    "nodes = 7\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(len(X_train.columns,))))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "\n",
    "# model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(7))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# # Define your DNN model\n",
    "# model = Sequential([\n",
    "#     Flatten(input_shape=(28, 28)),  # Input layer\n",
    "#     Dense(128, activation='relu'),  # Hidden layer\n",
    "#     Dense(10, activation='relu')  # Output layer\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# # Save the trained model\n",
    "# model.save('your_model.h5')\n",
    "\n",
    "# # Load your trained model\n",
    "# model = tf.keras.models.load_model('your_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Training the model\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Train on 659845 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-22 08:40:39.600307: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2024-05-22 08:40:39.606751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:67:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-05-22 08:40:39.606898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.53GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2024-05-22 08:40:39.606920: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-05-22 08:40:39.622463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2024-05-22 08:40:39.622566: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-05-22 08:40:39.624775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2024-05-22 08:40:39.625077: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2024-05-22 08:40:39.625558: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2024-05-22 08:40:39.626133: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-05-22 08:40:39.626224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-05-22 08:40:39.626232: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-22 08:40:39.626646: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 08:40:39.628261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-05-22 08:40:39.628296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2024-05-22 08:40:39.649651: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3699850000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659845/659845 [==============================] - 0s 1us/sample - loss: 8.6109 - accuracy: 0.0727\n",
      "Epoch 2/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 3.7405 - accuracy: 0.3299\n",
      "Epoch 3/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 2.8344 - accuracy: 0.6948\n",
      "Epoch 4/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 2.5269 - accuracy: 0.7557\n",
      "Epoch 5/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 2.1289 - accuracy: 0.7842\n",
      "Epoch 6/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 1.5345 - accuracy: 0.8008\n",
      "Epoch 7/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 1.0826 - accuracy: 0.8022\n",
      "Epoch 8/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.7268 - accuracy: 0.8027\n",
      "Epoch 9/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6967 - accuracy: 0.8028\n",
      "Epoch 10/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6929 - accuracy: 0.8028\n",
      "Epoch 11/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6889 - accuracy: 0.8028\n",
      "Epoch 12/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6839 - accuracy: 0.8028\n",
      "Epoch 13/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6781 - accuracy: 0.8028\n",
      "Epoch 14/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6708 - accuracy: 0.8028\n",
      "Epoch 15/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6616 - accuracy: 0.8028\n",
      "Epoch 16/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6604 - accuracy: 0.8028\n",
      "Epoch 17/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6458 - accuracy: 0.8028\n",
      "Epoch 18/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6289 - accuracy: 0.8028\n",
      "Epoch 19/1000\n",
      "659845/659845 [==============================] - 0s 1us/sample - loss: 0.6101 - accuracy: 0.8028\n",
      "---------------------------------------------------------------------------------\n",
      "ELAPSE TIME TRAINING MODEL:  0.12436915636062622 min\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Define your learning rate schedule function\n",
    "# def lr_schedule(epoch):\n",
    "#     # Your learning rate schedule logic here\n",
    "#     learning_rate = 0.1\n",
    "#     if epoch > 10:\n",
    "#         learning_rate = 0.01\n",
    "#     if epoch > 20:\n",
    "#         learning_rate = 0.001\n",
    "#     return learning_rate\n",
    "# lr_sched = LearningRateScheduler(lambda epoch: 1e-3 * (0.75 ** np.floor(epoch / 2)))\n",
    "\n",
    "# # Create a LearningRateScheduler callback\n",
    "# lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Training the model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Modify model.fit to include the EarlyStopping callback\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=len(X_train), callbacks=[early_stopping])\n",
    "\n",
    "# Pass the lr_scheduler callback to your model.fit() function\n",
    "# model.fit(X_train, y_train, callbacks=[lr_scheduler], ...)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('ELAPSE TIME TRAINING MODEL: ',(end - start)/60, 'min')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Model Prediction\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELAPSE TIME MODEL PREDICTION:  0.07332231998443603 min\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "80.2352966137656\n",
      "Counter({0: 226902, 2: 38054, 1: 16073, 3: 1351, 5: 205, 4: 202, 6: 5})\n",
      "Counter({0: 282789, 1: 3})\n",
      "80.2352966137656\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Model Prediction')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "start = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end = time.time()\n",
    "print('ELAPSE TIME MODEL PREDICTION: ',(end - start)/60, 'min')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "#print(y_pred)\n",
    "ynew = np.argmax(y_pred,axis = 1)\n",
    "#print(ynew)\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "#print(score)\n",
    "pred_label = label[ynew]\n",
    "#print(score)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# pd.crosstab(test['ALERT'], preds, rownames=['Actual ALERT'], colnames = ['Predicted ALERT'])\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy =accuracy_score(y_test, ynew)*100\n",
    "print(accuracy)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(y_test)\n",
    "print(label_counts)\n",
    "\n",
    "label_counts = Counter(ynew)\n",
    "print(label_counts)\n",
    "\n",
    "accuracy =accuracy_score(y_test, ynew)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample_df = X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2255405</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>5.990626e-07</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.021792</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Destination Port   Flow Duration   Total Fwd Packets  \\\n",
       "2255405           0.000809        0.000775            0.000009   \n",
       "\n",
       "          Total Backward Packets  Total Length of Fwd Packets  \\\n",
       "2255405                 0.000007                     0.000055   \n",
       "\n",
       "          Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
       "2255405                  5.990626e-07                0.001926   \n",
       "\n",
       "          Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
       "2255405                0.021792                 0.009696   \n",
       "\n",
       "          Fwd Packet Length Std  ...   act_data_pkt_fwd  \\\n",
       "2255405                     0.0  ...           0.000005   \n",
       "\n",
       "          min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
       "2255405               0.231884          0.0          0.0          0.0   \n",
       "\n",
       "          Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  \n",
       "2255405          0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1 rows x 77 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.03  0.    ... 0.    0.24  0.123]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.031 0.    ... 0.    0.243 0.124]\n",
      " ...\n",
      " [0.002 0.    0.    ... 0.    0.    0.   ]\n",
      " [0.256 0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.02  0.    ... 0.    0.029 0.015]]\n",
      "282792\n",
      "77\n",
      "(10000, 77)\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.    0.03  0.    ... 0.    0.24  0.123]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.031 0.    ... 0.    0.243 0.124]\n",
      " ...\n",
      " [0.002 0.    0.    ... 0.    0.    0.   ]\n",
      " [0.256 0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.02  0.    ... 0.    0.029 0.015]]\n",
      "(' ACK Flag Count', ' PSH Flag Count', ' Destination Port', ' Idle Max', 'Idle Mean', ' Avg Bwd Segment Size', ' URG Flag Count', ' Bwd Packet Length Mean', ' Idle Min', 'Fwd PSH Flags', ' Bwd Packet Length Std', 'Fwd IAT Total', ' Fwd IAT Std', ' Packet Length Std', ' Flow Duration', 'Init_Win_bytes_forward', ' Init_Win_bytes_backward', ' Bwd IAT Mean', ' Max Packet Length', ' Packet Length Variance', ' min_seg_size_forward', ' Fwd Packet Length Mean', ' Flow IAT Std', ' Fwd IAT Mean', 'Bwd Packet Length Max', ' Fwd Packet Length Max', ' Avg Fwd Segment Size', ' SYN Flag Count', ' Fwd IAT Max', 'Fwd Packets/s', ' Flow IAT Mean', ' Bwd IAT Min', 'Bwd IAT Total', ' Average Packet Size', 'FIN Flag Count', ' Packet Length Mean', ' Bwd IAT Max', ' Fwd Packet Length Min', ' Flow IAT Max', ' Down/Up Ratio', ' Min Packet Length', ' Idle Std', ' Bwd Packets/s', ' Fwd IAT Min', ' Flow IAT Min', ' Bwd IAT Std', ' Bwd Packet Length Min', ' ECE Flag Count', ' Subflow Fwd Bytes', ' Active Max', ' Fwd Packet Length Std', ' Active Std', ' RST Flag Count', ' Active Min', 'Active Mean', 'Total Length of Fwd Packets', ' CWE Flag Count', ' Fwd Header Length', ' Total Backward Packets', ' Bwd Header Length', 'Subflow Fwd Packets', ' act_data_pkt_fwd', ' Subflow Bwd Bytes', ' Fwd URG Flags', ' Total Fwd Packets', ' Total Length of Bwd Packets', ' Subflow Bwd Packets', 'Flow Bytes/s', ' Flow Packets/s', ' Bwd PSH Flags', ' Bwd URG Flags', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate')\n",
      "(463.935302734375, 402.7149963378906, 399.31915283203125, 238.25283813476562, 154.36766052246094, 131.41851806640625, 131.02227783203125, 124.22853088378906, 103.18561553955078, 93.41825866699219, 92.76582336425781, 88.93806457519531, 78.48825073242188, 71.02153778076172, 66.48965454101562, 58.98918151855469, 50.28451156616211, 48.71499252319336, 41.96174240112305, 34.30278015136719, 31.79106330871582, 29.75303077697754, 29.70506477355957, 26.2144718170166, 24.13035011291504, 23.580963134765625, 22.800504684448242, 21.898513793945312, 21.425495147705078, 20.781496047973633, 19.264368057250977, 19.042381286621094, 16.64261245727539, 16.53768539428711, 14.614204406738281, 10.12112808227539, 9.854266166687012, 9.408385276794434, 7.1397833824157715, 6.785140037536621, 5.917818069458008, 4.758838653564453, 4.426062107086182, 4.315563201904297, 3.896247625350952, 2.4934141635894775, 1.7868123054504395, 1.521551251411438, 1.1567940711975098, 0.9740171432495117, 0.8974344730377197, 0.8896690011024475, 0.576548159122467, 0.4444516599178314, 0.35693418979644775, 0.3172777593135834, 0.10748962312936783, 0.08794143050909042, 0.05783640593290329, 0.04846556484699249, 0.02553599700331688, 0.021386299282312393, 0.018595820292830467, 0.01829206570982933, 0.01168381329625845, 0.003962031565606594, 0.003054932691156864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "CPU times: user 1.16 s, sys: 345 ms, total: 1.5 s\n",
      "Wall time: 411 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(' ACK Flag Count',\n",
       " ' PSH Flag Count',\n",
       " ' Destination Port',\n",
       " ' Idle Max',\n",
       " 'Idle Mean',\n",
       " ' Avg Bwd Segment Size',\n",
       " ' URG Flag Count',\n",
       " ' Bwd Packet Length Mean',\n",
       " ' Idle Min',\n",
       " 'Fwd PSH Flags',\n",
       " ' Bwd Packet Length Std',\n",
       " 'Fwd IAT Total',\n",
       " ' Fwd IAT Std',\n",
       " ' Packet Length Std',\n",
       " ' Flow Duration',\n",
       " 'Init_Win_bytes_forward',\n",
       " ' Init_Win_bytes_backward',\n",
       " ' Bwd IAT Mean',\n",
       " ' Max Packet Length',\n",
       " ' Packet Length Variance',\n",
       " ' min_seg_size_forward',\n",
       " ' Fwd Packet Length Mean',\n",
       " ' Flow IAT Std',\n",
       " ' Fwd IAT Mean',\n",
       " 'Bwd Packet Length Max',\n",
       " ' Fwd Packet Length Max',\n",
       " ' Avg Fwd Segment Size',\n",
       " ' SYN Flag Count',\n",
       " ' Fwd IAT Max',\n",
       " 'Fwd Packets/s',\n",
       " ' Flow IAT Mean',\n",
       " ' Bwd IAT Min',\n",
       " 'Bwd IAT Total',\n",
       " ' Average Packet Size',\n",
       " 'FIN Flag Count',\n",
       " ' Packet Length Mean',\n",
       " ' Bwd IAT Max',\n",
       " ' Fwd Packet Length Min',\n",
       " ' Flow IAT Max',\n",
       " ' Down/Up Ratio',\n",
       " ' Min Packet Length',\n",
       " ' Idle Std',\n",
       " ' Bwd Packets/s',\n",
       " ' Fwd IAT Min',\n",
       " ' Flow IAT Min',\n",
       " ' Bwd IAT Std',\n",
       " ' Bwd Packet Length Min',\n",
       " ' ECE Flag Count',\n",
       " ' Subflow Fwd Bytes',\n",
       " ' Active Max',\n",
       " ' Fwd Packet Length Std',\n",
       " ' Active Std',\n",
       " ' RST Flag Count',\n",
       " ' Active Min',\n",
       " 'Active Mean',\n",
       " 'Total Length of Fwd Packets',\n",
       " ' CWE Flag Count',\n",
       " ' Fwd Header Length',\n",
       " ' Total Backward Packets',\n",
       " ' Bwd Header Length',\n",
       " 'Subflow Fwd Packets',\n",
       " ' act_data_pkt_fwd',\n",
       " ' Subflow Bwd Bytes',\n",
       " ' Fwd URG Flags',\n",
       " ' Total Fwd Packets',\n",
       " ' Total Length of Bwd Packets',\n",
       " ' Subflow Bwd Packets',\n",
       " 'Flow Bytes/s',\n",
       " ' Flow Packets/s',\n",
       " ' Bwd PSH Flags',\n",
       " ' Bwd URG Flags',\n",
       " 'Fwd Avg Bytes/Bulk',\n",
       " ' Fwd Avg Packets/Bulk',\n",
       " ' Fwd Avg Bulk Rate',\n",
       " ' Bwd Avg Bytes/Bulk',\n",
       " ' Bwd Avg Packets/Bulk',\n",
       " 'Bwd Avg Bulk Rate')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create an analyzer for the model\n",
    "analyzer = innvestigate.create_analyzer(\"integrated_gradients\", model)\n",
    "\n",
    "# Replace X_test with your input data\n",
    "\n",
    "# X_test = np.random.rand(100, 28, 28)  # Example input data\n",
    "\n",
    "# X_test2 = X_test.frac(0.001, random_state=42)\n",
    "\n",
    "# Perform LRP analysis on the input data\n",
    "analysis = analyzer.analyze(X_test)\n",
    "\n",
    "# Perform LRP analysis on a certain number of samples\n",
    "# analysis = analyzer.analyze(X_test.sample(10000))\n",
    "\n",
    "#uncomment for single sample\n",
    "# analysis = analyzer.analyze(single_sample_df)\n",
    "\n",
    "# Print or use the analysis results as needed\n",
    "print(analysis)\n",
    "\n",
    "print(len(X_test))\n",
    "print(len(X_test.columns))\n",
    "names = X_test.columns\n",
    "print(analysis.shape)\n",
    "print(type(analysis))\n",
    "scores = pd.DataFrame(analysis)\n",
    "print(analysis)\n",
    "scores_abs = scores.abs()\n",
    "\n",
    "# Calculate the sum of each column\n",
    "sum_of_columns = scores_abs.sum(axis=0)\n",
    "\n",
    "names = list(names)\n",
    "\n",
    "names\n",
    "\n",
    "sum_of_columns = list(sum_of_columns)\n",
    "\n",
    "sum_of_columns\n",
    "# type(sum_of_columns)\n",
    "# # sorted_series = sum_of_columns.sort_values(ascending=False)\n",
    "\n",
    "# print(\"Sorted Series in descending order:\")\n",
    "# print(sorted_series)\n",
    "### Results\n",
    "# names = ['John', 'Alice', 'Bob', 'Emily']\n",
    "# sum_of_columns = [10, 5, 15, 8]\n",
    "\n",
    "# Zip the two lists together\n",
    "combined = list(zip(names, sum_of_columns))\n",
    "\n",
    "# Sort the combined list in descending order based on the values from sum_of_columns\n",
    "sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Unzip the sorted_combined list to separate names and sum_of_columns\n",
    "sorted_names, sorted_sum_of_columns = zip(*sorted_combined)\n",
    "\n",
    "print(sorted_names)\n",
    "print(sorted_sum_of_columns)\n",
    "\n",
    "sorted_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.301  0.     0.    ...  0.     0.     0.   ]\n",
      " [ 0.002  0.     0.    ...  0.     0.     0.   ]\n",
      " [ 0.     0.     0.    ...  0.     0.     0.   ]\n",
      " ...\n",
      " [ 0.002  0.     0.    ...  0.     0.     0.   ]\n",
      " [ 0.     0.    -0.    ...  0.     0.     0.   ]\n",
      " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
      "282792\n",
      "77\n",
      "(10000, 77)\n",
      "<class 'numpy.ndarray'>\n",
      "[[ 0.301  0.     0.    ...  0.     0.     0.   ]\n",
      " [ 0.002  0.     0.    ...  0.     0.     0.   ]\n",
      " [ 0.     0.     0.    ...  0.     0.     0.   ]\n",
      " ...\n",
      " [ 0.002  0.     0.    ...  0.     0.     0.   ]\n",
      " [ 0.     0.    -0.    ...  0.     0.     0.   ]\n",
      " [ 0.     0.     0.    ...  0.     0.     0.   ]]\n",
      "(' ACK Flag Count', ' PSH Flag Count', ' Destination Port', ' Idle Max', 'Idle Mean', ' URG Flag Count', ' Bwd Packet Length Mean', ' Avg Bwd Segment Size', 'Fwd PSH Flags', ' Bwd Packet Length Std', ' Idle Min', 'Fwd IAT Total', ' Packet Length Std', ' min_seg_size_forward', ' Flow Duration', ' Fwd IAT Std', 'Init_Win_bytes_forward', ' Init_Win_bytes_backward', ' Bwd IAT Mean', ' Max Packet Length', ' Packet Length Variance', ' SYN Flag Count', 'Bwd Packet Length Max', ' Flow IAT Std', ' Fwd Packet Length Mean', ' Fwd IAT Mean', 'Fwd Packets/s', ' Fwd IAT Max', ' Fwd Packet Length Max', ' Bwd IAT Min', ' Avg Fwd Segment Size', 'Bwd IAT Total', ' Flow IAT Mean', ' Packet Length Mean', 'FIN Flag Count', ' Average Packet Size', ' Flow IAT Max', ' Bwd IAT Max', ' Fwd Packet Length Min', ' Down/Up Ratio', ' Idle Std', ' Fwd IAT Min', ' Bwd Packets/s', ' Flow IAT Min', ' Min Packet Length', ' Bwd Packet Length Min', ' Bwd IAT Std', ' Fwd Packet Length Std', ' Subflow Fwd Bytes', ' Active Max', ' Active Std', ' ECE Flag Count', ' Active Min', ' RST Flag Count', 'Active Mean', 'Total Length of Fwd Packets', ' CWE Flag Count', ' Fwd Header Length', ' Total Backward Packets', ' Bwd Header Length', 'Subflow Fwd Packets', ' Fwd URG Flags', ' act_data_pkt_fwd', ' Subflow Bwd Bytes', ' Total Fwd Packets', ' Subflow Bwd Packets', ' Total Length of Bwd Packets', 'Flow Bytes/s', ' Flow Packets/s', ' Bwd PSH Flags', ' Bwd URG Flags', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate')\n",
      "(480.050537109375, 411.5379638671875, 402.1454772949219, 216.6117401123047, 147.23553466796875, 144.6378936767578, 134.4598388671875, 113.1123046875, 99.01939392089844, 91.10275268554688, 89.34874725341797, 87.65155029296875, 80.47994995117188, 76.43875885009766, 70.57701110839844, 67.232421875, 58.57329177856445, 51.86328125, 51.20384216308594, 39.965003967285156, 34.49112319946289, 32.43508529663086, 32.41598129272461, 30.448556900024414, 25.79825210571289, 25.260543823242188, 23.334001541137695, 22.449356079101562, 21.486051559448242, 20.956518173217773, 20.37811279296875, 18.988842010498047, 18.051090240478516, 15.790151596069336, 14.310714721679688, 13.030256271362305, 10.31477165222168, 10.140816688537598, 7.487573146820068, 6.165596008300781, 5.365128517150879, 4.772945880889893, 3.9639644622802734, 3.5928359031677246, 3.5522918701171875, 3.371453285217285, 3.3380093574523926, 1.2474287748336792, 0.9108560681343079, 0.7855952382087708, 0.6313320398330688, 0.5847544074058533, 0.3915124535560608, 0.2854430079460144, 0.2793867588043213, 0.26963797211647034, 0.1074896827340126, 0.07973861694335938, 0.06059353053569794, 0.05274274945259094, 0.026336735114455223, 0.018292052671313286, 0.01780431531369686, 0.017439620569348335, 0.012031475082039833, 0.0038930398877710104, 0.0028528347611427307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "CPU times: user 931 ms, sys: 0 ns, total: 931 ms\n",
      "Wall time: 920 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(' ACK Flag Count',\n",
       " ' PSH Flag Count',\n",
       " ' Destination Port',\n",
       " ' Idle Max',\n",
       " 'Idle Mean',\n",
       " ' URG Flag Count',\n",
       " ' Bwd Packet Length Mean',\n",
       " ' Avg Bwd Segment Size',\n",
       " 'Fwd PSH Flags',\n",
       " ' Bwd Packet Length Std',\n",
       " ' Idle Min',\n",
       " 'Fwd IAT Total',\n",
       " ' Packet Length Std',\n",
       " ' min_seg_size_forward',\n",
       " ' Flow Duration',\n",
       " ' Fwd IAT Std',\n",
       " 'Init_Win_bytes_forward',\n",
       " ' Init_Win_bytes_backward',\n",
       " ' Bwd IAT Mean',\n",
       " ' Max Packet Length',\n",
       " ' Packet Length Variance',\n",
       " ' SYN Flag Count',\n",
       " 'Bwd Packet Length Max',\n",
       " ' Flow IAT Std',\n",
       " ' Fwd Packet Length Mean',\n",
       " ' Fwd IAT Mean',\n",
       " 'Fwd Packets/s',\n",
       " ' Fwd IAT Max',\n",
       " ' Fwd Packet Length Max',\n",
       " ' Bwd IAT Min',\n",
       " ' Avg Fwd Segment Size',\n",
       " 'Bwd IAT Total',\n",
       " ' Flow IAT Mean',\n",
       " ' Packet Length Mean',\n",
       " 'FIN Flag Count',\n",
       " ' Average Packet Size',\n",
       " ' Flow IAT Max',\n",
       " ' Bwd IAT Max',\n",
       " ' Fwd Packet Length Min',\n",
       " ' Down/Up Ratio',\n",
       " ' Idle Std',\n",
       " ' Fwd IAT Min',\n",
       " ' Bwd Packets/s',\n",
       " ' Flow IAT Min',\n",
       " ' Min Packet Length',\n",
       " ' Bwd Packet Length Min',\n",
       " ' Bwd IAT Std',\n",
       " ' Fwd Packet Length Std',\n",
       " ' Subflow Fwd Bytes',\n",
       " ' Active Max',\n",
       " ' Active Std',\n",
       " ' ECE Flag Count',\n",
       " ' Active Min',\n",
       " ' RST Flag Count',\n",
       " 'Active Mean',\n",
       " 'Total Length of Fwd Packets',\n",
       " ' CWE Flag Count',\n",
       " ' Fwd Header Length',\n",
       " ' Total Backward Packets',\n",
       " ' Bwd Header Length',\n",
       " 'Subflow Fwd Packets',\n",
       " ' Fwd URG Flags',\n",
       " ' act_data_pkt_fwd',\n",
       " ' Subflow Bwd Bytes',\n",
       " ' Total Fwd Packets',\n",
       " ' Subflow Bwd Packets',\n",
       " ' Total Length of Bwd Packets',\n",
       " 'Flow Bytes/s',\n",
       " ' Flow Packets/s',\n",
       " ' Bwd PSH Flags',\n",
       " ' Bwd URG Flags',\n",
       " 'Fwd Avg Bytes/Bulk',\n",
       " ' Fwd Avg Packets/Bulk',\n",
       " ' Fwd Avg Bulk Rate',\n",
       " ' Bwd Avg Bytes/Bulk',\n",
       " ' Bwd Avg Packets/Bulk',\n",
       " 'Bwd Avg Bulk Rate')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create an analyzer for the model\n",
    "analyzer = innvestigate.create_analyzer(\"lrp.z\", model)\n",
    "\n",
    "# Perform LRP analysis on the input data\n",
    "analysis = analyzer.analyze(X_test)\n",
    "\n",
    "# Perform LRP analysis on a certain number of samples\n",
    "# analysis = analyzer.analyze(X_test.sample(10000))\n",
    "\n",
    "#uncomment for single sample\n",
    "# analysis = analyzer.analyze(single_sample_df)\n",
    "\n",
    "# Print or use the analysis results as needed\n",
    "print(analysis)\n",
    "print(len(X_test))\n",
    "print(len(X_test.columns))\n",
    "names = X_test.columns\n",
    "print(analysis.shape)\n",
    "print(type(analysis))\n",
    "scores = pd.DataFrame(analysis)\n",
    "print(analysis)\n",
    "scores_abs = scores.abs()\n",
    "\n",
    "# Calculate the sum of each column\n",
    "sum_of_columns = scores_abs.sum(axis=0)\n",
    "\n",
    "names = list(names)\n",
    "\n",
    "names\n",
    "\n",
    "sum_of_columns = list(sum_of_columns)\n",
    "\n",
    "sum_of_columns\n",
    "# type(sum_of_columns)\n",
    "# # sorted_series = sum_of_columns.sort_values(ascending=False)\n",
    "\n",
    "# print(\"Sorted Series in descending order:\")\n",
    "# print(sorted_series)\n",
    "# names = ['John', 'Alice', 'Bob', 'Emily']\n",
    "# sum_of_columns = [10, 5, 15, 8]\n",
    "\n",
    "# Zip the two lists together\n",
    "combined = list(zip(names, sum_of_columns))\n",
    "\n",
    "# Sort the combined list in descending order based on the values from sum_of_columns\n",
    "sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Unzip the sorted_combined list to separate names and sum_of_columns\n",
    "sorted_names, sorted_sum_of_columns = zip(*sorted_combined)\n",
    "\n",
    "print(sorted_names)\n",
    "print(sorted_sum_of_columns)\n",
    "\n",
    "sorted_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Generating Explainer\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        col_name  feature_importance_vals\n",
      "46                PSH Flag Count                 0.211347\n",
      "0               Destination Port                 0.194768\n",
      "47                ACK Flag Count                 0.172430\n",
      "75                      Idle Max                 0.119976\n",
      "1                  Flow Duration                 0.109994\n",
      "30                 Fwd PSH Flags                 0.108459\n",
      "48                URG Flag Count                 0.100754\n",
      "54          Avg Bwd Segment Size                 0.096816\n",
      "20                 Fwd IAT Total                 0.093486\n",
      "65        Init_Win_bytes_forward                 0.086614\n",
      "73                     Idle Mean                 0.084154\n",
      "12        Bwd Packet Length Mean                 0.077557\n",
      "76                      Idle Min                 0.077397\n",
      "25                 Bwd IAT Total                 0.071244\n",
      "13         Bwd Packet Length Std                 0.056536\n",
      "40            Packet Length Mean                 0.056016\n",
      "23                   Fwd IAT Max                 0.053028\n",
      "41             Packet Length Std                 0.050971\n",
      "22                   Fwd IAT Std                 0.047549\n",
      "18                  Flow IAT Max                 0.045588\n",
      "28                   Bwd IAT Max                 0.045489\n",
      "44                SYN Flag Count                 0.044566\n",
      "66       Init_Win_bytes_backward                 0.033337\n",
      "39             Max Packet Length                 0.031455\n",
      "52           Average Packet Size                 0.030077\n",
      "26                  Bwd IAT Mean                 0.026598\n",
      "21                  Fwd IAT Mean                 0.026051\n",
      "43                FIN Flag Count                 0.022374\n",
      "36                 Fwd Packets/s                 0.021123\n",
      "17                  Flow IAT Std                 0.020832\n",
      "27                   Bwd IAT Std                 0.020795\n",
      "68          min_seg_size_forward                 0.020183\n",
      "10         Bwd Packet Length Max                 0.019158\n",
      "29                   Bwd IAT Min                 0.018088\n",
      "16                 Flow IAT Mean                 0.012860\n",
      "42        Packet Length Variance                 0.012822\n",
      "6          Fwd Packet Length Max                 0.010832\n",
      "8         Fwd Packet Length Mean                 0.010216\n",
      "24                   Fwd IAT Min                 0.009143\n",
      "38             Min Packet Length                 0.008607\n",
      "53          Avg Fwd Segment Size                 0.008290\n",
      "11         Bwd Packet Length Min                 0.008121\n",
      "7          Fwd Packet Length Min                 0.008020\n",
      "74                      Idle Std                 0.007874\n",
      "9          Fwd Packet Length Std                 0.005130\n",
      "37                 Bwd Packets/s                 0.004395\n",
      "51                 Down/Up Ratio                 0.004161\n",
      "19                  Flow IAT Min                 0.002692\n",
      "69                   Active Mean                 0.001547\n",
      "71                    Active Max                 0.001044\n",
      "70                    Active Std                 0.000870\n",
      "72                    Active Min                 0.000814\n",
      "62             Subflow Fwd Bytes                 0.000444\n",
      "49                CWE Flag Count                 0.000291\n",
      "4    Total Length of Fwd Packets                 0.000169\n",
      "32                 Fwd URG Flags                 0.000144\n",
      "34             Fwd Header Length                 0.000036\n",
      "3         Total Backward Packets                 0.000028\n",
      "35             Bwd Header Length                 0.000026\n",
      "64             Subflow Bwd Bytes                 0.000013\n",
      "61           Subflow Fwd Packets                 0.000012\n",
      "63           Subflow Bwd Packets                 0.000011\n",
      "67              act_data_pkt_fwd                 0.000010\n",
      "2              Total Fwd Packets                 0.000009\n",
      "5    Total Length of Bwd Packets                 0.000009\n",
      "15                Flow Packets/s                 0.000000\n",
      "58            Bwd Avg Bytes/Bulk                 0.000000\n",
      "60             Bwd Avg Bulk Rate                 0.000000\n",
      "59          Bwd Avg Packets/Bulk                 0.000000\n",
      "57             Fwd Avg Bulk Rate                 0.000000\n",
      "56          Fwd Avg Packets/Bulk                 0.000000\n",
      "55            Fwd Avg Bytes/Bulk                 0.000000\n",
      "50                ECE Flag Count                 0.000000\n",
      "31                 Bwd PSH Flags                 0.000000\n",
      "14                  Flow Bytes/s                 0.000000\n",
      "33                 Bwd URG Flags                 0.000000\n",
      "45                RST Flag Count                 0.000000\n",
      "---------------------------------------------------------------------------------\n",
      "Trial_ =[\n",
      "' PSH Flag Count',\n",
      "' Destination Port',\n",
      "' ACK Flag Count',\n",
      "' Idle Max',\n",
      "' Flow Duration',\n",
      "'Fwd PSH Flags',\n",
      "' URG Flag Count',\n",
      "' Avg Bwd Segment Size',\n",
      "'Fwd IAT Total',\n",
      "'Init_Win_bytes_forward',\n",
      "'Idle Mean',\n",
      "' Bwd Packet Length Mean',\n",
      "' Idle Min',\n",
      "'Bwd IAT Total',\n",
      "' Bwd Packet Length Std',\n",
      "' Packet Length Mean',\n",
      "' Fwd IAT Max',\n",
      "' Packet Length Std',\n",
      "' Fwd IAT Std',\n",
      "' Flow IAT Max',\n",
      "' Bwd IAT Max',\n",
      "' SYN Flag Count',\n",
      "' Init_Win_bytes_backward',\n",
      "' Max Packet Length',\n",
      "' Average Packet Size',\n",
      "' Bwd IAT Mean',\n",
      "' Fwd IAT Mean',\n",
      "'FIN Flag Count',\n",
      "'Fwd Packets/s',\n",
      "' Flow IAT Std',\n",
      "' Bwd IAT Std',\n",
      "' min_seg_size_forward',\n",
      "'Bwd Packet Length Max',\n",
      "' Bwd IAT Min',\n",
      "' Flow IAT Mean',\n",
      "' Packet Length Variance',\n",
      "' Fwd Packet Length Max',\n",
      "' Fwd Packet Length Mean',\n",
      "' Fwd IAT Min',\n",
      "' Min Packet Length',\n",
      "' Avg Fwd Segment Size',\n",
      "' Bwd Packet Length Min',\n",
      "' Fwd Packet Length Min',\n",
      "' Idle Std',\n",
      "' Fwd Packet Length Std',\n",
      "' Bwd Packets/s',\n",
      "' Down/Up Ratio',\n",
      "' Flow IAT Min',\n",
      "'Active Mean',\n",
      "' Active Max',\n",
      "' Active Std',\n",
      "' Active Min',\n",
      "' Subflow Fwd Bytes',\n",
      "' CWE Flag Count',\n",
      "'Total Length of Fwd Packets',\n",
      "' Fwd URG Flags',\n",
      "' Fwd Header Length',\n",
      "' Total Backward Packets',\n",
      "' Bwd Header Length',\n",
      "' Subflow Bwd Bytes',\n",
      "'Subflow Fwd Packets',\n",
      "' Subflow Bwd Packets',\n",
      "' act_data_pkt_fwd',\n",
      "' Total Fwd Packets',\n",
      "' Total Length of Bwd Packets',\n",
      "' Flow Packets/s',\n",
      "' Bwd Avg Bytes/Bulk',\n",
      "'Bwd Avg Bulk Rate',\n",
      "' Bwd Avg Packets/Bulk',\n",
      "' Fwd Avg Bulk Rate',\n",
      "' Fwd Avg Packets/Bulk',\n",
      "'Fwd Avg Bytes/Bulk',\n",
      "' ECE Flag Count',\n",
      "' Bwd PSH Flags',\n",
      "'Flow Bytes/s',\n",
      "' Bwd URG Flags',\n",
      "' RST Flag Count',\n",
      "---------------------------------------------------------------------------------\n",
      "CPU times: user 2min 19s, sys: 6.4 s, total: 2min 25s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_file_name = 'SHAPCIC.txt'\n",
    "with open(output_file_name, \"w\") as f:print('',file = f)\n",
    "\n",
    "###here\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Generating Explainer')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "samples = 2500\n",
    "\n",
    "# uncomment for single sample\n",
    "# samples = 1\n",
    "\n",
    "Label = label\n",
    "# df.pop('Label')\n",
    "#train.pop('Label')\n",
    "test = X_test\n",
    "train = X_train\n",
    "#df.pop('is_train')\n",
    "start_index = 0\n",
    "\n",
    "#end_index = len(test)\n",
    "end_index = samples\n",
    "#test = test[features]\n",
    "explainer = shap.DeepExplainer(model,train[start_index:end_index].values.astype('float'))\n",
    "shap_values = explainer.shap_values(test[start_index:end_index].values.astype('float'))\n",
    "# shap_values = explainer.shap_values(test[start_index:len(test)].values.astype('float'))\n",
    "\n",
    "# shap.summary_plot(shap_values = shap_values,\n",
    "#                  features = test[start_index:end_index],\n",
    "#                   class_names=[label[0],label[1],label[2],label[3],label[4],label[5],label[6]],show=False)\n",
    "\n",
    "# plt.savefig('DNN_Shap_Summary_Cicids.png')\n",
    "# plt.clf()\n",
    "\n",
    "vals= np.abs(shap_values).mean(1)\n",
    "feature_importance = pd.DataFrame(list(zip(train.columns, sum(vals))), columns=['col_name','feature_importance_vals'])\n",
    "feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)\n",
    "feature_importance.head()\n",
    "print(feature_importance.to_string())\n",
    "\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "# feature_importance_vals = 'feature_importance_vals'  # Replace with the name of the column you want to extract\n",
    "feature_val = feature_importance['feature_importance_vals'].tolist()\n",
    "\n",
    "# col_name = 'col_name'  # Replace with the name of the column you want to extract\n",
    "feature_name = feature_importance['col_name'].tolist()\n",
    "\n",
    "\n",
    "# for item1, item2 in zip(feature_name, feature_val):\n",
    "#     print(item1, item2)\n",
    "\n",
    "\n",
    "# Use zip to combine the two lists, sort based on list1, and then unzip them\n",
    "zipped_lists = list(zip(feature_name, feature_val))\n",
    "zipped_lists.sort(key=lambda x: x[1],reverse=True)\n",
    "\n",
    "# Convert the sorted result back into separate lists\n",
    "sorted_list1, sorted_list2 = [list(x) for x in zip(*zipped_lists)]\n",
    "\n",
    "for k in sorted_list1:\n",
    "  with open(output_file_name, \"a\") as f:print(\"df.pop('\",k,\"')\", sep='',file = f)\n",
    "with open(output_file_name, \"a\") as f:print(\"Trial_ =[\", file = f)\n",
    "print(\"Trial_ =[\")\n",
    "for k in sorted_list1:\n",
    "  with open(output_file_name, \"a\") as f:print(\"'\",k,\"',\", sep='', file = f)\n",
    "  print(\"'\",k,\"',\", sep='')\n",
    "with open(output_file_name, \"a\") as f:print(\"]\", file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # shap.summary_plot(shap_values = shap_values[0],\n",
    "# #                  features = test[start_index:end_index],\n",
    "# #                   class_names=[label[0],label[1],label[2],label[3],label[4],label[5],label[6]],show=False)\n",
    "\n",
    "\n",
    "# # plt.savefig('DNN_Shap_Summary_Beeswarms.png')\n",
    "# # plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "# print('---------------------------------------------------------------------------------')\n",
    "# print('Generating Sparsity Graph')\n",
    "# print('---------------------------------------------------------------------------------')\n",
    "# print('')\n",
    "\n",
    "# # Find the minimum and maximum values in the list\n",
    "# min_value = min(feature_val)\n",
    "# max_value = max(feature_val)\n",
    "\n",
    "# # Normalize the list to the range [0, 1]\n",
    "# normalized_list = []\n",
    "# for x in feature_val:\n",
    "#     if max_value - min_value == 0:\n",
    "#         normalized_list.append(0)\n",
    "#     else:\n",
    "#         normalized_list.append((x - min_value) / (max_value - min_value))\n",
    "   \n",
    "# # print(feature_name,normalized_list,'\\n')\n",
    "# # for item1, item2 in zip(feature_name, normalized_list):\n",
    "# #     print(item1, item2)\n",
    "\n",
    "# #calculating Sparsity\n",
    "\n",
    "# # Define the threshold\n",
    "# threshold = 1e-10\n",
    "\n",
    "# # Initialize a count variable to keep track of values below the threshold\n",
    "# count_below_threshold = 0\n",
    "\n",
    "# # Iterate through the list and count values below the threshold\n",
    "# for value in normalized_list:\n",
    "#     if value < threshold:\n",
    "#         count_below_threshold += 1\n",
    "\n",
    "# Sparsity = count_below_threshold/len(normalized_list)\n",
    "# Spar = []\n",
    "# print('Sparsity = ',Sparsity)\n",
    "# X_axis = []\n",
    "# #----------------------------------------------------------------------------\n",
    "# for i in range(0, 11):\n",
    "#     i/10\n",
    "#     threshold = i/10\n",
    "#     for value in normalized_list:\n",
    "#         if value < threshold:\n",
    "#             count_below_threshold += 1\n",
    "\n",
    "#     Sparsity = count_below_threshold/len(normalized_list)\n",
    "#     Spar.append(Sparsity)\n",
    "#     X_axis.append(i/10)\n",
    "#     count_below_threshold = 0\n",
    "\n",
    "\n",
    "# #---------------------------------------------------------------------------\n",
    "\n",
    "# with open(output_file_name, \"a\") as f:print('y_axis_RF = ', Spar ,'', file = f)\n",
    "# with open(output_file_name, \"a\") as f:print('x_axis_RF = ', X_axis ,'', file = f)\n",
    "\n",
    "# plt.clf()\n",
    "\n",
    "# # Create a plot\n",
    "# plt.plot(X_axis, Spar, marker='o', linestyle='-')\n",
    "\n",
    "# # Set labels for the axes\n",
    "# plt.xlabel('X-Axis')\n",
    "# plt.ylabel('Y-Axis')\n",
    "\n",
    "# # Set the title of the plot\n",
    "# plt.title('Values vs. X-Axis')\n",
    "\n",
    "# # Show the plot\n",
    "# # plt.show()\n",
    "# plt.savefig('sparsity.png')\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HITL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
