{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We First load the dataset and set the parameters to the model. For this experiment we are using DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Initializing DNN program\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Importing Libraries\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Defining Metric Equations\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Defining features of interest\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Loading Database\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Separating features and labels\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Counter({'Denial of Service': 642515, 'Port Scanning': 417040, 'None': 195521})\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Separating datasets\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Counter({'Denial of Service': 642515, 'Port Scanning': 417040, 'None': 195521})\n",
      "---------------------------------------------------------------------------------\n",
      "Separating Training and Testing db\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Defining the DNN model\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "---------------------------------------------------------------------------------\n",
      "Training the model\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Train on 878553 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 1/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 2.4376 - accuracy: 0.5235 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 2/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 1.8325 - accuracy: 0.5408 - lr: 0.0010\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 3/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 1.4397 - accuracy: 0.5574 - lr: 0.0010\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 4/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 1.1853 - accuracy: 0.5645 - lr: 0.0010\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 5/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 1.0460 - accuracy: 0.5723 - lr: 0.0010\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 6/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.9775 - accuracy: 0.5807 - lr: 0.0010\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 7/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.9388 - accuracy: 0.5870 - lr: 0.0010\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 8/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.9181 - accuracy: 0.5917 - lr: 0.0010\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 9/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.9048 - accuracy: 0.5971 - lr: 0.0010\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 10/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8947 - accuracy: 0.6044 - lr: 0.0010\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 11/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8849 - accuracy: 0.6136 - lr: 0.0010\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8750 - accuracy: 0.6245 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 13/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8743 - accuracy: 0.6248 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 14/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8735 - accuracy: 0.6252 - lr: 1.0000e-06\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 15/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8744 - accuracy: 0.6241 - lr: 1.0000e-07\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 16/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8747 - accuracy: 0.6246 - lr: 1.0000e-08\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 17/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8735 - accuracy: 0.6251 - lr: 1.0000e-09\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 18/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8746 - accuracy: 0.6257 - lr: 1.0000e-10\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 19/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8743 - accuracy: 0.6255 - lr: 1.0000e-11\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 1.000000082740371e-12.\n",
      "Epoch 20/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8740 - accuracy: 0.6257 - lr: 1.0000e-12\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.0000001044244145e-13.\n",
      "Epoch 21/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8741 - accuracy: 0.6249 - lr: 1.0000e-13\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.0000001179769417e-14.\n",
      "Epoch 22/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8741 - accuracy: 0.6253 - lr: 1.0000e-14\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0000001518582595e-15.\n",
      "Epoch 23/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8738 - accuracy: 0.6258 - lr: 1.0000e-15\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0000001095066122e-16.\n",
      "Epoch 24/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8743 - accuracy: 0.6248 - lr: 1.0000e-16\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0000000830368326e-17.\n",
      "Epoch 25/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8745 - accuracy: 0.6253 - lr: 1.0000e-17\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.0000000664932204e-18.\n",
      "Epoch 26/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8735 - accuracy: 0.6252 - lr: 1.0000e-18\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.000000045813705e-19.\n",
      "Epoch 27/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8741 - accuracy: 0.6254 - lr: 1.0000e-19\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.000000032889008e-20.\n",
      "Epoch 28/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8746 - accuracy: 0.6245 - lr: 1.0000e-20\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0000000490448793e-21.\n",
      "Epoch 29/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8740 - accuracy: 0.6249 - lr: 1.0000e-21\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0000000692397185e-22.\n",
      "Epoch 30/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8746 - accuracy: 0.6247 - lr: 1.0000e-22\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 1.0000000944832675e-23.\n",
      "Epoch 31/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8745 - accuracy: 0.6249 - lr: 1.0000e-23\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1.0000000787060494e-24.\n",
      "Epoch 32/1000\n",
      "878553/878553 [==============================] - 1s 2us/sample - loss: 0.8742 - accuracy: 0.6252 - lr: 1.0000e-24\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 1.0000001181490946e-25.\n",
      "Epoch 33/1000\n",
      "878553/878553 [==============================] - 2s 2us/sample - loss: 0.8743 - accuracy: 0.6252 - lr: 1.0000e-25\n",
      "---------------------------------------------------------------------------------\n",
      "ELAPSE TIME TRAINING MODEL:  0.8619534969329834 min\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Model Prediction\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "ELAPSE TIME MODEL PREDICTION:  0.11724696556727092 min\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "64.0157440581319\n",
      "Counter({0: 192898, 2: 125009, 1: 58616})\n",
      "Counter({0: 202814, 1: 173709})\n",
      "64.0157440581319\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "### DNN Regression\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Initializing DNN program')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "#---------------------------------------------------------------------\n",
    "# Importing Libraries\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Importing Libraries')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import LSTM\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.preprocessing import sequence\n",
    "#from keras.utils import pad_sequences\n",
    "#from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import shap\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.random.seed(0)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Defining metric equations\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining Metric Equations')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "def ACC(TP,TN,FP,FN):\n",
    "    Acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return Acc\n",
    "def ACC_2 (TP, FN):\n",
    "    ac = (TP/(TP+FN))\n",
    "    return ac\n",
    "def PRECISION(TP,FP):\n",
    "    Precision = TP/(TP+FP)\n",
    "    return Precision\n",
    "def RECALL(TP,FN):\n",
    "    Recall = TP/(TP+FN)\n",
    "    return Recall\n",
    "def F1(Recall, Precision):\n",
    "    F1 = 2 * Recall * Precision / (Recall + Precision)\n",
    "    return F1\n",
    "def BACC(TP,TN,FP,FN):\n",
    "    BACC =(TP/(TP+FN)+ TN/(TN+FP))*0.5\n",
    "    return BACC\n",
    "def MCC(TP,TN,FP,FN):\n",
    "    MCC = (TN*TP-FN*FP)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**.5)\n",
    "    return MCC\n",
    "def AUC_ROC(y_test_bin,y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    auc_avg = 0\n",
    "    counting = 0\n",
    "    for i in range(n_classes):\n",
    "      fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "     # plt.plot(fpr[i], tpr[i], color='darkorange', lw=2)\n",
    "      #print('AUC for Class {}: {}'.format(i+1, auc(fpr[i], tpr[i])))\n",
    "      auc_avg += auc(fpr[i], tpr[i])\n",
    "      counting = i+1\n",
    "    return auc_avg/counting\n",
    "#---------------------------------------------------------------------\n",
    "# Defining features of interest\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining features of interest')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "req_cols = ['FLOW_DURATION_MILLISECONDS','FIRST_SWITCHED',\n",
    "            'TOTAL_FLOWS_EXP','TCP_WIN_MSS_IN','LAST_SWITCHED',\n",
    "            'TCP_WIN_MAX_IN','TCP_WIN_MIN_IN','TCP_WIN_MIN_OUT',\n",
    "           'PROTOCOL','TCP_WIN_MAX_OUT','TCP_FLAGS',\n",
    "            'TCP_WIN_SCALE_OUT','TCP_WIN_SCALE_IN','SRC_TOS',\n",
    "            'DST_TOS','FLOW_ID','L4_SRC_PORT','L4_DST_PORT',\n",
    "           'MIN_IP_PKT_LEN','MAX_IP_PKT_LEN','TOTAL_PKTS_EXP',\n",
    "           'TOTAL_BYTES_EXP','IN_BYTES','IN_PKTS','OUT_BYTES','OUT_PKTS',\n",
    "            'ALERT']\n",
    "\n",
    "    # feature_selection =  [ \n",
    "    #     'TCP_WIN_SCALE_IN', \n",
    "    #     'TCP_WIN_MIN_IN', \n",
    "    #     'TCP_WIN_MAX_IN', \n",
    "    #     'TCP_WIN_MSS_IN', \n",
    "    #     'TCP_FLAGS',\n",
    "    #     'PROTOCOL', \n",
    "    #     'FLOW_DURATION_MILLISECONDS', \n",
    "    #     # 'TCP_WIN_MAX_OUT', \n",
    "    #     'TCP_WIN_MIN_OUT', \n",
    "    #     # 'SRC_TOS', \n",
    "    #     # 'DST_TOS',\n",
    "    #     'Label' \n",
    "    #     ]\n",
    "#---------------------------------------------------------------------\n",
    "#Load Databases from csv file\n",
    "address = '/home/oarreche@ads.iu.edu/HITL/sensor/sensor_db'\n",
    "print('Loading Database')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "fraction = 0.1\n",
    "fraction2 = 0.01\n",
    "\n",
    "#Denial of Service\n",
    "df0 = pd.read_csv (address + '/dos-03-15-2022-15-44-32.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df1 = pd.read_csv (address + '/dos-03-16-2022-13-45-18.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df2 = pd.read_csv (address + '/dos-03-17-2022-16-22-53.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df3 = pd.read_csv (address + '/dos-03-18-2022-19-27-05.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df4 = pd.read_csv (address + '/dos-03-19-2022-20-01-53.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df5 = pd.read_csv (address + '/dos-03-20-2022-14-27-54.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "#Malware\n",
    "#df6 = pd.read_csv ('sensor_db/malware-03-25-2022-17-57-07.csv', usecols=req_cols)\n",
    "\n",
    "#Normal\n",
    "df7 = pd.read_csv  (address + '/normal-03-15-2022-15-43-44.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "df8 = pd.read_csv  (address + '/normal-03-16-2022-13-44-27.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "df9 = pd.read_csv  (address + '/normal-03-17-2022-16-21-30.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "df10 = pd.read_csv (address + '/normal-03-18-2022-19-17-31.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "df11 = pd.read_csv (address + '/normal-03-18-2022-19-25-48.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "df12 = pd.read_csv (address + '/normal-03-19-2022-20-01-16.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "df13 = pd.read_csv (address + '/normal-03-20-2022-14-27-30.csv', usecols=req_cols).sample(frac = fraction2)\n",
    "\n",
    "\n",
    "#PortScanning\n",
    "df14 = pd.read_csv  (address + '/portscanning-03-15-2022-15-44-06.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df15 = pd.read_csv  (address + '/portscanning-03-16-2022-13-44-50.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df16 = pd.read_csv  (address + '/portscanning-03-17-2022-16-22-53.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df17 = pd.read_csv  (address + '/portscanning-03-18-2022-19-27-05.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df18 = pd.read_csv  (address + '/portscanning-03-19-2022-20-01-45.csv', usecols=req_cols).sample(frac = fraction)\n",
    "df19 = pd.read_csv  (address + '/portscanning-03-20-2022-14-27-49.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "frames = [df0, df1, df2, df3, df4, df5, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17, df18, df19]\n",
    "\n",
    "# fraction = 0.1\n",
    "\n",
    "#concat data frames\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "# shuffle the DataFrame rows\n",
    "# df = df.sample(frac = fraction)\n",
    "\n",
    "y = df.pop('ALERT')\n",
    "X = df\n",
    "\n",
    "df_max_scaled = X\n",
    "for col in df_max_scaled.columns:\n",
    "    t = abs(df_max_scaled[col].max())\n",
    "    df_max_scaled[col] = df_max_scaled[col]/t\n",
    "df_max_scaled\n",
    "df = df_max_scaled.assign( Label = y)\n",
    "#df\n",
    "df = df.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# Separate features and labels \n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating features and labels')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "y = df.pop('Label')\n",
    "X = df\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# Separate features and labels \n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating datasets')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "test2 = X.assign(ALERT = y)\n",
    "\n",
    "Dos_samples = test2[test2['ALERT'] == 'Denial of Service']\n",
    "Normal_samples = test2[test2['ALERT'] == 'None']\n",
    "PS_samples = test2[test2['ALERT'] == 'Port Scanning']\n",
    "Attack_samples = test2[test2['ALERT'] == 'Attack']\n",
    "\n",
    "PS_y = PS_samples.pop('ALERT')\n",
    "Dos_y = Dos_samples.pop('ALERT')\n",
    "Normal_y = Normal_samples.pop('ALERT')\n",
    "Attack_y = Attack_samples.pop('ALERT')\n",
    "\n",
    "test2.pop('ALERT')\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "df = X.assign( Label = y)\n",
    "\n",
    "y, label = pd.factorize(y)\n",
    "# y_test, label = pd.factorize(test['Label'])\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating Training and Testing db')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.7,random_state=42)\n",
    "df = X.assign( Label = y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Now you can use Keras modules directly from tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Flatten\n",
    "import innvestigate\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining the DNN model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "\n",
    "nodes_first_layer = 128\n",
    "nodes_second_layer = 64\n",
    "nodes_third_layer = 32\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(len(X_train.columns,))))\n",
    "\n",
    "# First dense layer\n",
    "model.add(tf.keras.layers.Dense(nodes_first_layer, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))  # Dropout layer follows the first dense layer\n",
    "\n",
    "# Second dense layer\n",
    "model.add(tf.keras.layers.Dense(nodes_second_layer, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))  # Dropout layer follows the second dense layer\n",
    "\n",
    "# Third dense layer\n",
    "model.add(tf.keras.layers.Dense(nodes_third_layer, activation='relu'))\n",
    "\n",
    "# Output layer, assuming the task involves classification into 3 classes\n",
    "model.add(tf.keras.layers.Dense(3))  # No activation here, add 'softmax' when using the model for prediction\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Training the model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 10:\n",
    "        return lr * 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Modify model.fit to include the EarlyStopping callback\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=len(X_train), callbacks=[early_stopping,lr_scheduler])\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('ELAPSE TIME TRAINING MODEL: ',(end - start)/60, 'min')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Model Prediction')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "start = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end = time.time()\n",
    "print('ELAPSE TIME MODEL PREDICTION: ',(end - start)/60, 'min')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "#print(y_pred)\n",
    "ynew = np.argmax(y_pred,axis = 1)\n",
    "#print(ynew)\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "#print(score)\n",
    "pred_label = label[ynew]\n",
    "#print(score)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy =accuracy_score(y_test, ynew)*100\n",
    "print(accuracy)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(y_test)\n",
    "print(label_counts)\n",
    "\n",
    "label_counts = Counter(ynew)\n",
    "print(label_counts)\n",
    "\n",
    "accuracy =accuracy_score(y_test, ynew)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train\n",
    "test = X_test\n",
    "labels_train = y_train\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model,train.values.astype('float'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to test sample with the waterfall plot\n",
    "def waterfall_explanator(sample):\n",
    "\n",
    "    # explainer = shap.DeepExplainer(model,train.values.astype('float'))\n",
    "    shap_values = explainer.shap_values(sample.values.astype('float'))\n",
    "    # print('SHAP VALUES',shap_values)\n",
    "    # print('SHAP VALUES LEN',len(shap_values))\n",
    "    index = np.argmax(model.predict(sample)) # Prediction of the sample\n",
    "    # print('INDEX PREDICTION',index)\n",
    "    # print('SHAP VALUES FOR INDEX',shap_values[index])\n",
    "    vals= np.abs(shap_values[index])\n",
    "    # print('ABSOLUTE VALUES',vals)\n",
    "    # vals = vals.mean()\n",
    "    # print('ABSOLUTE VALUUS MEAN',vals)\n",
    "    # vals= np.abs(shap_values).mean(index)\n",
    "    feature_importance = pd.DataFrame(list(zip(train.columns, sum(vals))), columns=['col_name','feature_importance_vals'])\n",
    "    feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)\n",
    "    feature_importance.head()\n",
    "\n",
    "    shap_val = list(feature_importance['feature_importance_vals'])\n",
    "    prediction = index\n",
    "    feature_name = list(feature_importance['col_name'])\n",
    "    feature_val = []\n",
    "    for j in feature_name:\n",
    "        feature_val.append(float(sample[j]))\n",
    "    # print(prediction, shap_val,feature_val,feature_name)        \n",
    "\n",
    "    return (prediction, shap_val,feature_val,feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness_all(single_class_samples,number_samples, number_of_features_pertubation):\n",
    "    Bucket = {\n",
    "    '0.0': 0,\n",
    "    '0.1':0,\n",
    "    '0.2':0,\n",
    "    '0.3':0,\n",
    "    '0.4':0,\n",
    "    '0.5':0,\n",
    "    '0.6':0,\n",
    "    '0.7':0,\n",
    "    '0.8':0,\n",
    "    '0.9':0,\n",
    "    '1.0':0,\n",
    "\n",
    "           }\n",
    "    # Counter_chart = 0\n",
    "    Counter_all_samples = 0\n",
    "    counter_samples_changed_class = 0\n",
    "    print('------------------------------------------------')\n",
    "    print('Initiating Completeness Experiment')\n",
    "    print('------------------------------------------------')\n",
    "    for i in range(0,number_samples):\n",
    "        #select sample\n",
    "        try:\n",
    "            sample = single_class_samples[i:i+1]\n",
    "        except:\n",
    "            break # break if there more samples requested than samples in the dataset\n",
    "        # Explanate the original sample\n",
    "        u = waterfall_explanator(sample)\n",
    "        #select top 5 features from the original sample\n",
    "        top_k_features = []\n",
    "        top_k_features.append(u[3][0]) #append first feature\n",
    "        break_condition = False\n",
    "        for k in range(1,number_of_features_pertubation):\n",
    "            for j in range(11):  # 11 steps to include 1.0 (0 to 10)\n",
    "                if break_condition == True: break\n",
    "                perturbation = j / 10.0  # Divide by 10 to get steps of 0.1\n",
    "                temp_var = sample[top_k_features[k-1]]\n",
    "                result = np.where((temp_var - perturbation) < 0, True, False)\n",
    "                if result < 0: \n",
    "                    sample[top_k_features[k-1]] = 1 - perturbation\n",
    "                else: sample[top_k_features[k-1]] = temp_var - perturbation\n",
    "                # sample[top_k_features[k-1]] = perturbation\n",
    "                v = waterfall_explanator(sample)\n",
    "                if v[0] != u[0]: \n",
    "                    # print(str(perturbation))\n",
    "                    Bucket[str(perturbation)] += 1              \n",
    "                    break_condition = True\n",
    "                    counter_samples_changed_class += 1     \n",
    "                    # Bucket[str(perturbation)] = counter_samples_changed_class              \n",
    "                    break\n",
    "                else: sample[top_k_features[k-1]] = abs(temp_var - 1) # set the sample feature value as the symetric opposite\n",
    "            # print(u)\n",
    "            top_k_features.append(u[3][k]) #append second, third feature .. and so on\n",
    "            if break_condition == True: break\n",
    "        Counter_all_samples += 1\n",
    "        progress  = 100*Counter_all_samples/number_samples\n",
    "        if progress%10 == 0: print('Progress', progress ,'%')\n",
    "    # print('Number of Normal samples that changed classification: ',counter_samples_changed_class)\n",
    "    # print('Number of all samples analyzed: ',Counter_all_samples)\n",
    "    # for key in Bucket:\n",
    "    #     Bucket[key]=number_samples - Bucket[key]\n",
    "    # Bucket['0.0'] = number_samples\n",
    "    # for key in Bucket:\n",
    "    #     Bucket[key]=Bucket[key]\n",
    "    dict = Bucket\n",
    "    temp = 0\n",
    "    for k in dict:\n",
    "        dict[k] = dict[k] + temp\n",
    "        temp = dict[k]\n",
    "    total = number_samples\n",
    "    y_axis = []\n",
    "    for k in dict:\n",
    "        dict[k] = abs(dict[k] - total)\n",
    "        y_axis.append(dict[k]/total)    \n",
    "    return(counter_samples_changed_class,Counter_all_samples,y_axis)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_samples = 500\n",
    "# K_feat =  Dos_samples.shape[1]\n",
    "K_feat = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dos_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Initiating Completeness Experiment\n",
      "------------------------------------------------\n",
      "Progress 10.0 %\n",
      "Progress 20.0 %\n",
      "Progress 30.0 %\n",
      "Progress 40.0 %\n",
      "Progress 50.0 %\n",
      "Progress 60.0 %\n",
      "Progress 70.0 %\n",
      "Progress 80.0 %\n",
      "Progress 90.0 %\n",
      "Progress 100.0 %\n",
      "(500, 500, [1.0, 0.066, 0.066, 0.016, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
      "Number of DoS samples that changed classification:  500\n",
      "Number of all samples analyzed:  500\n",
      "100.0 % - samples are complete \n"
     ]
    }
   ],
   "source": [
    "num_samples = K_samples\n",
    "num_feat_pertubation = K_feat\n",
    "p = completeness_all(Dos_samples,num_samples,num_feat_pertubation)\n",
    "print(p)\n",
    "print('Number of DoS samples that changed classification: ',p[0])\n",
    "print('Number of all samples analyzed: ',p[1])\n",
    "percentage = 100*p[0]/p[1]\n",
    "print(percentage,'%','- samples are complete ')\n",
    "y_axis_dos = p[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'DNN_DL_SML_Completeness.txt'\n",
    "with open(output_file_name, \"w\") as f:print('',file = f)\n",
    "with open(output_file_name, \"a\") as f:print('y_axis_dos = [',y_axis_dos ,']',file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Initiating Completeness Experiment\n",
      "------------------------------------------------\n",
      "Progress 10.0 %\n",
      "Progress 20.0 %\n",
      "Progress 30.0 %\n",
      "Progress 40.0 %\n",
      "Progress 50.0 %\n",
      "Progress 60.0 %\n",
      "Progress 70.0 %\n",
      "Progress 80.0 %\n",
      "Progress 90.0 %\n",
      "Progress 100.0 %\n",
      "(483, 500, [0.388, 0.07, 0.066, 0.052, 0.052, 0.046, 0.042, 0.038, 0.038, 0.036, 0.034])\n",
      "Number of Normal samples that changed classification:  483\n",
      "Number of all samples analyzed:  500\n",
      "96.6 % - samples are complete \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "p = completeness_all(Normal_samples,num_samples,num_feat_pertubation)\n",
    "print(p)\n",
    "print('Number of Normal samples that changed classification: ',p[0])\n",
    "print('Number of all samples analyzed: ',p[1])\n",
    "percentage = 100*p[0]/p[1]\n",
    "print(percentage,'%','- samples are complete ')\n",
    "y_axis_normal = p[2]\n",
    "with open(output_file_name, \"a\") as f:print('y_axis_normal = [',y_axis_normal ,']',file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Initiating Completeness Experiment\n",
      "------------------------------------------------\n",
      "Progress 10.0 %\n",
      "Progress 20.0 %\n",
      "Progress 30.0 %\n",
      "Progress 40.0 %\n",
      "Progress 50.0 %\n",
      "Progress 60.0 %\n",
      "Progress 70.0 %\n",
      "Progress 80.0 %\n",
      "Progress 90.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = completeness_all(PS_samples,num_samples,num_feat_pertubation)\n",
    "print(p)\n",
    "print('Number of PS samples that changed classification: ',p[0])\n",
    "print('Number of all samples analyzed: ',p[1])\n",
    "percentage = 100*p[0]/p[1]\n",
    "print(percentage,'%','- samples are complete ')\n",
    "y_axis_ps = p[2]\n",
    "with open(output_file_name, \"a\") as f:print('y_axis_ps = [',y_axis_ps ,']',file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.clf()\n",
    "x_axis = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1]\n",
    "y_axis_dos = [1.0, 0.066, 0.066, 0.016, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
    "y_axis_normal = [0.388, 0.07, 0.066, 0.052, 0.052, 0.046, 0.042, 0.038, 0.038, 0.036, 0.034] \n",
    "y_axis_ps = [ 0.14, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
    "\n",
    "# Plot the first line\n",
    "plt.plot(x_axis, y_axis_dos, label='DoS', color='blue', linestyle='--', marker='o')\n",
    "\n",
    "# Plot the second line\n",
    "plt.plot(x_axis, y_axis_normal, label='Normal', color='red', linestyle='--', marker='x')\n",
    "\n",
    "# Plot the third line\n",
    "plt.plot(x_axis, y_axis_ps, label='Port Scan', color='green', linestyle='--', marker='s')\n",
    "\n",
    "# # Plot the fourth line\n",
    "# plt.plot(x_axis, y_axis_infiltration, label='Infiltration', color='purple', linestyle='--', marker='p')\n",
    "\n",
    "# # Plot the fifth line\n",
    "# plt.plot(x_axis, y_axis_bot, label='Bot', color='orange', linestyle='--', marker='h')\n",
    "\n",
    "# # Plot the sixth line\n",
    "# plt.plot(x_axis, y_axis_web, label='Web Attack', color='magenta', linestyle='--', marker='+')\n",
    "\n",
    "# # Plot the seventh line\n",
    "# plt.plot(x_axis, y_axis_brute, label='Brute Force', color='cyan', linestyle='--', marker='_')\n",
    "\n",
    "# Enable grid lines (both major and minor grids)\n",
    "plt.grid()\n",
    "\n",
    "# Customize grid lines (optional)\n",
    "# plt.grid()\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Perturbations')\n",
    "plt.ylabel('Samples remaining')\n",
    "plt.legend()\n",
    "\n",
    "# Set the title of the plot\n",
    "# plt.title('Accuracy x Features - SHAP SML')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.savefig('GRAPH_PERT_SHAP_CIC.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
