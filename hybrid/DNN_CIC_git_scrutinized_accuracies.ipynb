{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score, precision_score, \n",
    "                             recall_score, f1_score, balanced_accuracy_score, \n",
    "                             matthews_corrcoef)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "import shap\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import innvestigate\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.random.seed(0)\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_metrics (name_model,predictions,true_labels):\n",
    "\n",
    "    name = name_model\n",
    "    pred_label = predictions\n",
    "    y_test_01 = true_labels \n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(name, file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test_01, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test_01))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    Acc = accuracy_score(y_test_01, pred_label)\n",
    "    Precision = precision_score(y_test_01, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test_01, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test_01, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test_01, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test_01, pred_label)\n",
    "\n",
    "\n",
    "    # voting_acc_01 = Acc\n",
    "    # voting_pre_01 = Precision\n",
    "    # weighed_avg_rec_01 = Recall\n",
    "    # weighed_avg_f1_01 = F1\n",
    "    # weighed_avg_bacc_01 = BACC\n",
    "    # weighed_avg_mcc_01 = MCC\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n",
    "    return Acc, Precision, Recall, F1, BACC, MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = \"CIC_Base.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Loading Databases\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Normalizing database\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Separating features and labels\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Counter({'BENIGN': 756652, 'Dos/Ddos': 127047, 'PortScan': 52987, 'Brute Force': 4594, 'Web Attack': 716, 'Bot': 628, 'Infiltration': 13})\n",
      "---------------------------------------------------------------------------------\n",
      "Separating Training and Testing db\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "req_cols = [\n",
    "    \n",
    "    ' Packet Length Std', ' Total Length of Bwd Packets', ' Subflow Bwd Bytes',\n",
    "    ' Destination Port', ' Packet Length Variance', ' Bwd Packet Length Mean',' Avg Bwd Segment Size',\n",
    "    'Bwd Packet Length Max', ' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
    "    ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' Average Packet Size', ' Packet Length Mean',\n",
    "    ' Max Packet Length',\n",
    "    ' Down/Up Ratio', ' Fwd URG Flags', ' Flow IAT Std', 'Subflow Fwd Packets', ' Flow Packets/s', ' URG Flag Count', 'FIN Flag Count', ' Bwd Packets/s', 'Bwd Avg Bulk Rate'\n",
    "    , ' act_data_pkt_fwd', ' Fwd Packet Length Std', ' Bwd Avg Bytes/Bulk', ' Active Max', ' Flow IAT Max', ' min_seg_size_forward', ' Bwd Packet Length Std', ' Fwd IAT Std', ' Fwd Avg Bulk Rate', ' Fwd Packet Length Mean', ' Fwd Packet Length Max', ' Idle Std', ' CWE Flag Count', 'Fwd IAT Total'\n",
    "    \n",
    "    , ' ACK Flag Count', ' Bwd URG Flags', ' Flow IAT Min', ' Flow IAT Mean', ' Total Backward Packets', ' Fwd Avg Packets/Bulk', 'Fwd Avg Bytes/Bulk', ' SYN Flag Count', ' Min Packet Length', ' Fwd Packet Length Min', 'Idle Mean', 'Fwd PSH Flags', ' Fwd IAT Min'\n",
    "     \n",
    "    ,  ' Fwd Header Length', ' RST Flag Count', ' Idle Max', ' PSH Flag Count', ' Bwd Header Length', ' ECE Flag Count', ' Subflow Bwd Packets', 'Active Mean', 'Flow Bytes/s', ' Bwd IAT Mean', ' Avg Fwd Segment Size', ' Bwd Packet Length Min', ' Active Std', ' Bwd IAT Min', ' Flow Duration', 'Fwd Packets/s', ' Fwd IAT Max', 'Bwd IAT Total', ' Idle Min', ' Bwd PSH Flags', ' Bwd Avg Packets/Bulk', ' Total Fwd Packets', ' Active Min', ' Bwd IAT Std', ' Fwd IAT Mean', ' Bwd IAT Max'\n",
    "            \n",
    "            , ' Label']\n",
    "\n",
    "# Information gain top 10 features\n",
    "top10 = [' Average Packet Size',\n",
    "          ' Packet Length Std', \n",
    "          ' Packet Length Variance', \n",
    "          ' Packet Length Mean',\n",
    "            ' Destination Port', \n",
    "            ' Subflow Bwd Bytes', \n",
    "            ' Total Length of Bwd Packets', \n",
    "            ' Avg Bwd Segment Size', \n",
    "            ' Bwd Packet Length Mean',  \n",
    "            'Bwd Packet Length Max', \n",
    "            ' Label']\n",
    "\n",
    "\n",
    "\n",
    "# req_cols = top10\n",
    "\n",
    "# req_cols = [' Destination Port',' Flow Duration',' Total Fwd Packets',' Total Backward Packets','Total Length of Fwd Packets',' Total Length of Bwd Packets',' Label']\n",
    "#---------------------------------------------------------------------\n",
    "#Load Databases from csv file\n",
    "\n",
    "path_str = '/home/oarreche@ads.iu.edu/HITL/cicids/cicids_db/'\n",
    "fraction = 1\n",
    "#---------------------------------------------------------------------\n",
    "#Load Databases from csv file\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Loading Databases')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "\n",
    "df0 = pd.read_csv (path_str + 'Wednesday-workingHours.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "df1 = pd.read_csv (path_str + 'Tuesday-WorkingHours.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df2 = pd.read_csv (path_str +'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df3 = pd.read_csv (path_str +'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df4 = pd.read_csv (path_str +'Monday-WorkingHours.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df5 = pd.read_csv (path_str +'Friday-WorkingHours-Morning.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df6 = pd.read_csv (path_str +'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "\n",
    "df7 = pd.read_csv (path_str +'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', usecols=req_cols).sample(frac = fraction)\n",
    "\n",
    "frames = [df0, df1, df2, df3, df4, df5, df6, df7]\n",
    "\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "df = df.sample(frac = 0.333)\n",
    "\n",
    "\n",
    "\n",
    "# IG popping unwandted columns descriptive accuracy\n",
    "\n",
    "# df.pop(' min_seg_size_forward')\n",
    "# df.pop(' PSH Flag Count')\n",
    "# df.pop(' ACK Flag Count')\n",
    "# df.pop('Init_Win_bytes_forward')\n",
    "# df.pop(' Destination Port')\n",
    "\n",
    "# df.pop(' Bwd Packet Length Mean')\n",
    "# df.pop('Fwd Packets/s')\n",
    "# df.pop(' Init_Win_bytes_backward')\n",
    "# df.pop(' Packet Length Mean')\n",
    "# df.pop(' Packet Length Std')\n",
    "\n",
    "# df.pop(' Bwd Packet Length Std')\n",
    "# df.pop(' Avg Bwd Segment Size')\n",
    "# df.pop(' Packet Length Variance')\n",
    "# df.pop(' Flow Duration')\n",
    "# df.pop(' Max Packet Length')\n",
    "# df.pop(' Flow IAT Max')\n",
    "# df.pop(' Idle Max')\n",
    "# df.pop('Bwd Packet Length Max')\n",
    "# df.pop(' Fwd IAT Max')\n",
    "# df.pop(' URG Flag Count')\n",
    "# df.pop('Fwd PSH Flags')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df.pop(' Min Packet Length')\n",
    "# df.pop('Idle Mean')\n",
    "# df.pop(' Fwd Packet Length Min')\n",
    "# df.pop(' Average Packet Size')\n",
    "# df.pop(' Idle Min')\n",
    "# df.pop('Bwd IAT Total')\n",
    "# df.pop('Fwd IAT Total')\n",
    "# df.pop(' Fwd Packet Length Max')\n",
    "# df.pop(' Avg Fwd Segment Size')\n",
    "# df.pop(' SYN Flag Count')\n",
    "# df.pop(' Fwd Packet Length Mean')\n",
    "# df.pop(' Flow IAT Std')\n",
    "# df.pop(' Down/Up Ratio')\n",
    "# df.pop(' Fwd IAT Mean')\n",
    "# df.pop('FIN Flag Count')\n",
    "# df.pop(' Bwd Packets/s')\n",
    "# df.pop(' Fwd Packet Length Std')\n",
    "# df.pop(' Flow IAT Mean')\n",
    "# df.pop(' Bwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Std')\n",
    "# df.pop(' Bwd IAT Mean')\n",
    "\n",
    "# df.pop(' Bwd IAT Std')\n",
    "# df.pop(' Bwd IAT Max')\n",
    "# df.pop(' Bwd IAT Min')\n",
    "# df.pop(' Fwd IAT Min')\n",
    "# df.pop(' Idle Std')\n",
    "# df.pop(' Active Max')\n",
    "# df.pop(' RST Flag Count')\n",
    "# df.pop(' Subflow Fwd Bytes')\n",
    "# df.pop(' ECE Flag Count')\n",
    "# df.pop(' Flow IAT Min')\n",
    "# df.pop('Total Length of Fwd Packets')\n",
    "# df.pop(' Active Std')\n",
    "# df.pop(' Active Min')\n",
    "# df.pop(' Bwd Header Length')\n",
    "# df.pop(' Fwd Header Length')\n",
    "# df.pop('Active Mean')\n",
    "# df.pop(' Total Fwd Packets')\n",
    "# df.pop(' Total Backward Packets')\n",
    "# df.pop('Subflow Fwd Packets')\n",
    "# df.pop(' act_data_pkt_fwd')\n",
    "# df.pop(' Subflow Bwd Bytes')\n",
    "# df.pop(' Fwd URG Flags')\n",
    "# df.pop(' CWE Flag Count')\n",
    "# df.pop(' Subflow Bwd Packets')\n",
    "# df.pop(' Total Length of Bwd Packets')\n",
    "# df.pop('Flow Bytes/s')\n",
    "# df.pop(' Flow Packets/s')\n",
    "# df.pop(' Bwd PSH Flags')\n",
    "# df.pop(' Bwd URG Flags')\n",
    "# df.pop('Fwd Avg Bytes/Bulk')\n",
    "# df.pop(' Fwd Avg Packets/Bulk')\n",
    "# df.pop(' Fwd Avg Bulk Rate')\n",
    "# df.pop(' Bwd Avg Bytes/Bulk')\n",
    "# df.pop(' Bwd Avg Packets/Bulk')\n",
    "# df.pop('Bwd Avg Bulk Rate')\n",
    "\n",
    "# LRP popping unwandted columns descriptive accuracy\n",
    "##########################################\n",
    "\n",
    "df.pop(' min_seg_size_forward')\n",
    "df.pop(' Flow Duration')\n",
    "df.pop(' Max Packet Length')\n",
    "df.pop(' PSH Flag Count')\n",
    "df.pop(' Bwd Packet Length Mean')\n",
    "\n",
    "df.pop('Bwd Packet Length Max')\n",
    "df.pop('Fwd IAT Total')\n",
    "df.pop(' Bwd IAT Max')\n",
    "df.pop(' ACK Flag Count')\n",
    "df.pop('Bwd IAT Total')\n",
    "\n",
    "df.pop(' URG Flag Count')\n",
    "df.pop(' Idle Min')\n",
    "df.pop(' Packet Length Mean')\n",
    "df.pop('Init_Win_bytes_forward')\n",
    "df.pop(' Average Packet Size')\n",
    "df.pop(' Avg Bwd Segment Size')\n",
    "df.pop(' Packet Length Std')\n",
    "df.pop(' Flow IAT Max')\n",
    "df.pop(' Fwd IAT Std')\n",
    "df.pop('Fwd PSH Flags')\n",
    "\n",
    "df.pop(' Bwd Packet Length Std')\n",
    "df.pop(' Idle Max')\n",
    "df.pop(' Packet Length Variance')\n",
    "df.pop(' Init_Win_bytes_backward')\n",
    "df.pop(' Fwd IAT Mean')\n",
    "df.pop(' Flow IAT Std')\n",
    "df.pop('Idle Mean')\n",
    "df.pop(' SYN Flag Count')\n",
    "df.pop(' Fwd Packet Length Mean')\n",
    "df.pop(' Bwd Packet Length Min')\n",
    "df.pop(' Fwd Packet Length Std')\n",
    "df.pop(' Bwd IAT Std')\n",
    "df.pop('FIN Flag Count')\n",
    "df.pop(' Avg Fwd Segment Size')\n",
    "df.pop(' Idle Std')\n",
    "df.pop(' Fwd IAT Max')\n",
    "df.pop(' Flow IAT Mean')\n",
    "df.pop(' Bwd IAT Mean')\n",
    "df.pop(' Destination Port')\n",
    "df.pop(' Down/Up Ratio')\n",
    "\n",
    "# df.pop('Fwd Packet Length Max')\n",
    "# df.pop('Fwd Packets/s')\n",
    "# df.pop('Min Packet Length')\n",
    "# df.pop('Bwd IAT Min')\n",
    "# df.pop('Fwd IAT Min')\n",
    "# df.pop('Fwd Packet Length Min')\n",
    "# df.pop('Bwd Packets/s')\n",
    "# df.pop('Active Mean')\n",
    "# df.pop('Fwd Header Length')\n",
    "# df.pop('Active Std')\n",
    "# df.pop('Active Min')\n",
    "# df.pop('Flow IAT Min')\n",
    "# df.pop('Active Max')\n",
    "# df.pop('Total Length of Fwd Packets')\n",
    "# df.pop('Subflow Fwd Bytes')\n",
    "# df.pop('RST Flag Count')\n",
    "# df.pop('CWE Flag Count')\n",
    "# df.pop('Fwd URG Flags')\n",
    "# df.pop('Total Fwd Packets')\n",
    "# df.pop('Subflow Fwd Packets')\n",
    "# df.pop('Bwd Header Length')\n",
    "# df.pop('Subflow Bwd Packets')\n",
    "# df.pop('Total Backward Packets')\n",
    "# df.pop('Subflow Bwd Bytes')\n",
    "# df.pop('act_data_pkt_fwd')\n",
    "# df.pop('ECE Flag Count')\n",
    "# df.pop('Total Length of Bwd Packets')\n",
    "# df.pop('Flow Bytes/s')\n",
    "# df.pop('Flow Packets/s')\n",
    "# df.pop('Bwd PSH Flags')\n",
    "# df.pop('Bwd URG Flags')\n",
    "# df.pop('Fwd Avg Bytes/Bulk')\n",
    "# df.pop('Fwd Avg Packets/Bulk')\n",
    "# df.pop('Fwd Avg Bulk Rate')\n",
    "# df.pop('Bwd Avg Bytes/Bulk')\n",
    "# df.pop('Bwd Avg Packets/Bulk')\n",
    "# df.pop('Bwd Avg Bulk Rate')\n",
    "\n",
    "\n",
    "# DeepLift popping unwandted columns descriptive accuracy\n",
    "\n",
    "# df.pop(' PSH Flag Count')\n",
    "# df.pop(' ACK Flag Count')\n",
    "# df.pop(' Bwd Packet Length Mean')\n",
    "# df.pop('Init_Win_bytes_forward')\n",
    "# df.pop(' Bwd Packet Length Std')\n",
    "\n",
    "# df.pop('Fwd Packets/s')\n",
    "# df.pop(' Packet Length Std')\n",
    "# df.pop(' Packet Length Variance')\n",
    "# df.pop(' Destination Port')\n",
    "# df.pop(' Avg Bwd Segment Size')\n",
    "\n",
    "# df.pop(' Packet Length Mean')\n",
    "# df.pop(' URG Flag Count')\n",
    "# df.pop(' Idle Max')\n",
    "# df.pop(' Flow IAT Max')\n",
    "# df.pop('Fwd PSH Flags')\n",
    "# df.pop(' Flow Duration')\n",
    "# df.pop(' Max Packet Length')\n",
    "# df.pop('Bwd Packet Length Max')\n",
    "# df.pop(' Fwd IAT Max')\n",
    "# df.pop('FIN Flag Count')\n",
    "# df.pop(' min_seg_size_forward')\n",
    "\n",
    "# df.pop('Idle Mean')\n",
    "# df.pop(' Idle Min')\n",
    "# df.pop(' Init_Win_bytes_backward')\n",
    "# df.pop('Bwd IAT Total')\n",
    "# df.pop('Fwd IAT Total')\n",
    "# df.pop(' Average Packet Size')\n",
    "# df.pop(' Flow IAT Std')\n",
    "# df.pop(' Min Packet Length')\n",
    "# df.pop(' SYN Flag Count')\n",
    "# df.pop(' Fwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Mean')\n",
    "# df.pop(' Bwd Packet Length Min')\n",
    "# df.pop(' Fwd IAT Std')\n",
    "# df.pop(' Fwd Packet Length Max')\n",
    "# df.pop(' Fwd Packet Length Mean')\n",
    "# df.pop(' Fwd Packet Length Std')\n",
    "# df.pop(' Flow IAT Mean')\n",
    "# df.pop(' Avg Fwd Segment Size')\n",
    "# df.pop(' Bwd IAT Max')\n",
    "# df.pop(' Bwd IAT Mean')\n",
    "# df.pop(' Down/Up Ratio')\n",
    "\n",
    "# df.pop(' Bwd IAT Min')\n",
    "# df.pop(' Fwd IAT Min')\n",
    "# df.pop(' Bwd IAT Std')\n",
    "# df.pop(' Bwd Packets/s')\n",
    "# df.pop(' Idle Std')\n",
    "# df.pop(' Active Max')\n",
    "# df.pop(' Flow IAT Min')\n",
    "# df.pop(' Subflow Fwd Bytes')\n",
    "# df.pop('Total Length of Fwd Packets')\n",
    "# df.pop(' Active Std')\n",
    "# df.pop(' RST Flag Count')\n",
    "# df.pop(' Active Min')\n",
    "# df.pop('Active Mean')\n",
    "# df.pop(' ECE Flag Count')\n",
    "# df.pop(' CWE Flag Count')\n",
    "# df.pop(' Fwd URG Flags')\n",
    "# df.pop(' Total Backward Packets')\n",
    "# df.pop(' act_data_pkt_fwd')\n",
    "# df.pop(' Total Fwd Packets')\n",
    "# df.pop(' Subflow Bwd Bytes')\n",
    "# df.pop('Subflow Fwd Packets')\n",
    "# df.pop(' Fwd Header Length')\n",
    "# df.pop(' Bwd Header Length')\n",
    "# df.pop(' Subflow Bwd Packets')\n",
    "# df.pop(' Total Length of Bwd Packets')\n",
    "# df.pop('Bwd Avg Bulk Rate')\n",
    "# df.pop(' Bwd Avg Packets/Bulk')\n",
    "# df.pop(' Bwd Avg Bytes/Bulk')\n",
    "# df.pop(' Fwd Avg Bulk Rate')\n",
    "# df.pop(' Fwd Avg Packets/Bulk')\n",
    "# df.pop(' Bwd PSH Flags')\n",
    "# df.pop('Flow Bytes/s')\n",
    "# df.pop(' Flow Packets/s')\n",
    "# df.pop(' Bwd URG Flags')\n",
    "# df.pop('Fwd Avg Bytes/Bulk')\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Normalize database\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Normalizing database')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "df_max_scaled = df.copy()\n",
    "\n",
    "y = df_max_scaled[' Label'].replace({'DDoS' :'Dos/Ddos' ,'DoS GoldenEye': 'Dos/Ddos', 'DoS Hulk': 'Dos/Ddos', 'DoS Slowhttptest': 'Dos/Ddos', 'DoS slowloris': 'Dos/Ddos', 'Heartbleed': 'Dos/Ddos','FTP-Patator': 'Brute Force', 'SSH-Patator': 'Brute Force','Web Attack - Brute Force': 'Web Attack', 'Web Attack - Sql Injection': 'Web Attack', 'Web Attack - XSS': 'Web Attack'})\n",
    "\n",
    "df_max_scaled.pop(' Label')\n",
    "\n",
    "\n",
    "df_max_scaled\n",
    "for col in df_max_scaled.columns:\n",
    "    t = abs(df_max_scaled[col].max())\n",
    "    df_max_scaled[col] = df_max_scaled[col]/t\n",
    "df_max_scaled\n",
    "df = df_max_scaled.assign( Label = y)\n",
    "#df\n",
    "df = df.fillna(0)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# Separate features and labels \n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating features and labels')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "y = df.pop('Label')\n",
    "X = df\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "df = X.assign( Label = y)\n",
    "\n",
    "y, label = pd.factorize(y)\n",
    "\n",
    "# Separate Training and Testing db\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Separating Training and Testing db')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.7,random_state=42)\n",
    "df = X.assign( Label = y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining the DNN model\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining the DNN model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "# dropout_rate = 0.01\n",
    "nodes = 7\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(len(X_train.columns,))))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(nodes, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(7))\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Training the model\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Train on 659845 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 22:29:07.823478: W tensorflow/c/c_api.cc:304] Operation '{name:'training_12/Adam/learning_rate/Assign' id:4789 op device:{requested: '', assigned: ''} def:{{{node training_12/Adam/learning_rate/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_12/Adam/learning_rate, training_12/Adam/learning_rate/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659845/659845 [==============================] - 0s 0us/sample - loss: 3.8919 - accuracy: 0.1845\n",
      "Epoch 2/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1235 - accuracy: 0.7769\n",
      "Epoch 3/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1754 - accuracy: 0.7844\n",
      "Epoch 4/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2764 - accuracy: 0.7871\n",
      "Epoch 5/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2926 - accuracy: 0.7882\n",
      "Epoch 6/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2897 - accuracy: 0.7891\n",
      "Epoch 7/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2888 - accuracy: 0.7907\n",
      "Epoch 8/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2658 - accuracy: 0.7910\n",
      "Epoch 9/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2415 - accuracy: 0.7929\n",
      "Epoch 10/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.2061 - accuracy: 0.7945\n",
      "Epoch 11/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1990 - accuracy: 0.7952\n",
      "Epoch 12/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1929 - accuracy: 0.7956\n",
      "Epoch 13/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1863 - accuracy: 0.7961\n",
      "Epoch 14/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1792 - accuracy: 0.7987\n",
      "Epoch 15/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1709 - accuracy: 0.7993\n",
      "Epoch 16/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1608 - accuracy: 0.8001\n",
      "Epoch 17/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.1518 - accuracy: 0.8009\n",
      "Epoch 18/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.0900 - accuracy: 0.8015\n",
      "Epoch 19/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.0730 - accuracy: 0.8023\n",
      "Epoch 20/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.0611 - accuracy: 0.8028\n",
      "Epoch 21/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.0149 - accuracy: 0.8028\n",
      "Epoch 22/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 2.0023 - accuracy: 0.8028\n",
      "Epoch 23/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9871 - accuracy: 0.8028\n",
      "Epoch 24/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9804 - accuracy: 0.8028\n",
      "Epoch 25/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9783 - accuracy: 0.8028\n",
      "Epoch 26/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9817 - accuracy: 0.8028\n",
      "Epoch 27/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9869 - accuracy: 0.8028\n",
      "Epoch 28/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9885 - accuracy: 0.8028\n",
      "Epoch 29/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9825 - accuracy: 0.8028\n",
      "Epoch 30/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9745 - accuracy: 0.8028\n",
      "Epoch 31/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9679 - accuracy: 0.8028\n",
      "Epoch 32/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9643 - accuracy: 0.8028\n",
      "Epoch 33/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9631 - accuracy: 0.8028\n",
      "Epoch 34/1000\n",
      "659845/659845 [==============================] - 0s 0us/sample - loss: 1.9628 - accuracy: 0.8028\n",
      "---------------------------------------------------------------------------------\n",
      "ELAPSE TIME TRAINING MODEL:  0.10076463222503662 min\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Training the model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=len(X_train), callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('ELAPSE TIME TRAINING MODEL: ',(end - start)/60, 'min')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Model Prediction\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "2025-02-05 22:29:13.760106: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_13/BiasAdd' id:4629 op device:{requested: '', assigned: ''} def:{{{node dense_13/BiasAdd}} = BiasAdd[T=DT_FLOAT, _has_manual_control_dependencies=true, data_format=\"NHWC\"](dense_13/MatMul, dense_13/BiasAdd/ReadVariableOp)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELAPSE TIME MODEL PREDICTION:  0.05771315097808838 min\n",
      "---------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "2025-02-05 22:29:17.218983: W tensorflow/c/c_api.cc:304] Operation '{name:'loss_6/mul' id:4693 op device:{requested: '', assigned: ''} def:{{{node loss_6/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_6/mul/x, loss_6/dense_13_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  80.23423576338793\n",
      "Counter({0: 226902, 2: 38054, 1: 16073, 3: 1351, 5: 205, 4: 202, 6: 5})\n",
      "Counter({0: 282786, 2: 6})\n",
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.80      1.00      0.89    226902\n",
      "    PortScan       0.00      0.00      0.00     16073\n",
      "    Dos/Ddos       0.00      0.00      0.00     38054\n",
      " Brute Force       0.00      0.00      0.00      1351\n",
      "         Bot       0.00      0.00      0.00       202\n",
      "  Web Attack       0.00      0.00      0.00       205\n",
      "Infiltration       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.80    282792\n",
      "   macro avg       0.11      0.14      0.13    282792\n",
      "weighted avg       0.64      0.80      0.71    282792\n",
      "\n",
      "True label counts: Counter({0: 226902, 2: 38054, 1: 16073, 3: 1351, 5: 205, 4: 202, 6: 5})\n",
      "Predicted label counts: Counter({0: 282786, 2: 6})\n",
      "Accuracy per class:\n",
      "BENIGN: 100.00%\n",
      "PortScan: 0.00%\n",
      "Dos/Ddos: 0.00%\n",
      "Brute Force: 0.00%\n",
      "Bot: 0.00%\n",
      "Web Attack: 0.00%\n",
      "Infiltration: 0.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Model Prediction')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "start = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "end = time.time()\n",
    "print('ELAPSE TIME MODEL PREDICTION: ',(end - start)/60, 'min')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "\n",
    "#print(y_pred)\n",
    "ynew = np.argmax(y_pred,axis = 1)\n",
    "#print(ynew)\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "#print(score)\n",
    "pred_label = label[ynew]\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "accuracy =accuracy_score(y_test, ynew)*100\n",
    "print('accuracy ',accuracy)\n",
    "\n",
    "label_counts = Counter(y_test)\n",
    "print(label_counts)\n",
    "\n",
    "label_counts = Counter(ynew)\n",
    "print(label_counts)\n",
    "\n",
    "from sklearn.metrics import  classification_report\n",
    "\n",
    "# Print the classification report for accuracy per class type\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, ynew, target_names=label))\n",
    "\n",
    "# Count occurrences of each class in the true labels\n",
    "label_counts_true = Counter(y_test)\n",
    "print('True label counts:', label_counts_true)\n",
    "\n",
    "# Count occurrences of each class in the predicted labels\n",
    "label_counts_pred = Counter(ynew)\n",
    "print('Predicted label counts:', label_counts_pred)\n",
    "\n",
    "\n",
    "# Calculate accuracy per class\n",
    "class_accuracies = {}\n",
    "for class_label in np.unique(y_test):\n",
    "    class_indices = np.where(y_test == class_label)\n",
    "    class_accuracy = accuracy_score(y_test[class_indices], ynew[class_indices]) * 100\n",
    "    class_accuracies[label[class_label]] = class_accuracy\n",
    "\n",
    "print('Accuracy per class:')\n",
    "for class_label, class_accuracy in class_accuracies.items():\n",
    "    print(f'{class_label}: {class_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "          0    1    2    3    4    5    6\n",
      "0  226896.0  6.0  0.0  0.0  0.0  0.0  0.0\n",
      "1   16073.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2   38054.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3    1351.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4     202.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "5     205.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "6       5.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.8023423576338793\n",
      "Precision total:  0.1146227687569904\n",
      "Recall total:  0.1428533652665657\n",
      "F1 total:  0.12719041564923753\n",
      "BACC total:  0.1428533652665657\n",
      "MCC total:  -0.0018698556250128088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8023423576338793,\n",
       " 0.1146227687569904,\n",
       " 0.1428533652665657,\n",
       " 0.12719041564923753,\n",
       " 0.1428533652665657,\n",
       " -0.0018698556250128088)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_metrics('dnn', ynew, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample_df = X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Flow Bytes/s</th>\n",
       "      <th>Flow Packets/s</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Bwd Avg Bulk Rate</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>Subflow Bwd Packets</th>\n",
       "      <th>Subflow Bwd Bytes</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2255405</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>5.990626e-07</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.021792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667e-08</td>\n",
       "      <td>1.666667e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5.990626e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total Fwd Packets   Total Backward Packets  \\\n",
       "2255405            0.000009                 0.000007   \n",
       "\n",
       "         Total Length of Fwd Packets   Total Length of Bwd Packets  \\\n",
       "2255405                     0.000055                  5.990626e-07   \n",
       "\n",
       "          Fwd Packet Length Max   Fwd Packet Length Min  Flow Bytes/s  \\\n",
       "2255405                0.001926                0.021792           0.0   \n",
       "\n",
       "          Flow Packets/s   Flow IAT Min   Fwd IAT Min  ...  Bwd Avg Bulk Rate  \\\n",
       "2255405              0.0   1.666667e-08  1.666667e-08  ...                0.0   \n",
       "\n",
       "         Subflow Fwd Packets   Subflow Fwd Bytes   Subflow Bwd Packets  \\\n",
       "2255405             0.000009            0.000055              0.000007   \n",
       "\n",
       "          Subflow Bwd Bytes   act_data_pkt_fwd  Active Mean   Active Std  \\\n",
       "2255405        5.990626e-07           0.000005          0.0          0.0   \n",
       "\n",
       "          Active Max   Active Min  \n",
       "2255405          0.0          0.0  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 22:29:27.570012: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_12/MatMul/ReadVariableOp' id:4602 op device:{requested: '', assigned: ''} def:{{{node dense_12/MatMul/ReadVariableOp}} = ReadVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT](dense_12/kernel)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:27.648244: W tensorflow/c/c_api.cc:304] Operation '{name:'dense_13/MatMul/ReadVariableOp' id:4626 op device:{requested: '', assigned: ''} def:{{{node dense_13/MatMul/ReadVariableOp}} = ReadVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT](dense_13/kernel)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:27.721612: W tensorflow/c/c_api.cc:304] Operation '{name:'ones_like_6/Const' id:4911 op device:{requested: '', assigned: ''} def:{{{node ones_like_6/Const}} = Const[_has_manual_control_dependencies=true, dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:27.901984: W tensorflow/c/c_api.cc:304] Operation '{name:'Variable_6/Assign' id:4931 op device:{requested: '', assigned: ''} def:{{{node Variable_6/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](Variable_6, Variable_6/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "2025-02-05 22:29:34.502312: W tensorflow/c/c_api.cc:304] Operation '{name:'multiply_18/mul' id:4985 op device:{requested: '', assigned: ''} def:{{{node multiply_18/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](reduce_mean_6/Mean, subtract_6/sub)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fwd Packets/s', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Bwd Packets/s', ' Min Packet Length', ' Fwd IAT Min', ' Fwd Header Length', ' Active Max', ' Bwd IAT Min', ' Bwd Header Length', ' Flow IAT Min', ' Active Min', 'Total Length of Fwd Packets', ' RST Flag Count', ' ECE Flag Count', ' Active Std', 'Active Mean', ' Subflow Fwd Bytes', ' Total Fwd Packets', ' Subflow Bwd Bytes', ' CWE Flag Count', ' Total Backward Packets', ' Total Length of Bwd Packets', 'Subflow Fwd Packets', ' act_data_pkt_fwd', ' Fwd URG Flags', ' Subflow Bwd Packets', 'Flow Bytes/s', ' Flow Packets/s', ' Bwd PSH Flags', ' Bwd URG Flags', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate')\n",
      "(1444.1380615234375, 674.5863647460938, 415.43426513671875, 364.6036376953125, 267.9099426269531, 229.65235900878906, 110.36612701416016, 97.85243225097656, 58.65562057495117, 51.449851989746094, 44.023563385009766, 35.35984420776367, 33.0189208984375, 23.782833099365234, 22.890151977539062, 20.900348663330078, 14.630152702331543, 8.639073371887207, 3.240492582321167, 2.6470930576324463, 2.240614652633667, 1.6457598209381104, 1.4124962091445923, 1.0097295045852661, 0.7999857664108276, 0.6018325090408325, 0.3769761621952057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "CPU times: user 26 s, sys: 668 ms, total: 26.7 s\n",
      "Wall time: 8.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Fwd Packets/s',\n",
       " ' Fwd Packet Length Max',\n",
       " ' Fwd Packet Length Min',\n",
       " ' Bwd Packets/s',\n",
       " ' Min Packet Length',\n",
       " ' Fwd IAT Min',\n",
       " ' Fwd Header Length',\n",
       " ' Active Max',\n",
       " ' Bwd IAT Min',\n",
       " ' Bwd Header Length',\n",
       " ' Flow IAT Min',\n",
       " ' Active Min',\n",
       " 'Total Length of Fwd Packets',\n",
       " ' RST Flag Count',\n",
       " ' ECE Flag Count',\n",
       " ' Active Std',\n",
       " 'Active Mean',\n",
       " ' Subflow Fwd Bytes',\n",
       " ' Total Fwd Packets',\n",
       " ' Subflow Bwd Bytes',\n",
       " ' CWE Flag Count',\n",
       " ' Total Backward Packets',\n",
       " ' Total Length of Bwd Packets',\n",
       " 'Subflow Fwd Packets',\n",
       " ' act_data_pkt_fwd',\n",
       " ' Fwd URG Flags',\n",
       " ' Subflow Bwd Packets',\n",
       " 'Flow Bytes/s',\n",
       " ' Flow Packets/s',\n",
       " ' Bwd PSH Flags',\n",
       " ' Bwd URG Flags',\n",
       " 'Fwd Avg Bytes/Bulk',\n",
       " ' Fwd Avg Packets/Bulk',\n",
       " ' Fwd Avg Bulk Rate',\n",
       " ' Bwd Avg Bytes/Bulk',\n",
       " ' Bwd Avg Packets/Bulk',\n",
       " 'Bwd Avg Bulk Rate')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Create an analyzer for the model\n",
    "analyzer = innvestigate.create_analyzer(\"integrated_gradients\", model)\n",
    "\n",
    "analysis = analyzer.analyze(X_test)\n",
    "\n",
    "# Perform LRP analysis on a certain number of samples\n",
    "# analysis = analyzer.analyze(X_test.sample(10000))\n",
    "\n",
    "#uncomment for single sample\n",
    "# analysis = analyzer.analyze(single_sample_df)\n",
    "\n",
    "names = X_test.columns\n",
    "\n",
    "scores = pd.DataFrame(analysis)\n",
    "scores_abs = scores.abs()\n",
    "\n",
    "# Calculate the sum of each column\n",
    "sum_of_columns = scores_abs.sum(axis=0)\n",
    "\n",
    "names = list(names)\n",
    "\n",
    "sum_of_columns = list(sum_of_columns)\n",
    "\n",
    "# Zip the two lists together\n",
    "combined = list(zip(names, sum_of_columns))\n",
    "\n",
    "# Sort the combined list in descending order based on the values from sum_of_columns\n",
    "sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Unzip the sorted_combined list to separate names and sum_of_columns\n",
    "sorted_names, sorted_sum_of_columns = zip(*sorted_combined)\n",
    "\n",
    "print(sorted_names)\n",
    "print(sorted_sum_of_columns)\n",
    "\n",
    "sorted_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 22:29:36.099616: W tensorflow/c/c_api.cc:304] Operation '{name:'bias_13/Assign' id:5029 op device:{requested: '', assigned: ''} def:{{{node bias_13/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](bias_13, bias_13/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.200783: W tensorflow/c/c_api.cc:304] Operation '{name:'gradients_81/MaxNeuronSelection_6/Max_grad/range' id:5039 op device:{requested: '', assigned: ''} def:{{{node gradients_81/MaxNeuronSelection_6/Max_grad/range}} = Range[Tidx=DT_INT32, _class=[\"loc:@MaxNeuronSelection_6/Max\"], _has_manual_control_dependencies=true](gradients_81/MaxNeuronSelection_6/Max_grad/range/start, gradients_81/MaxNeuronSelection_6/Max_grad/Size, gradients_81/MaxNeuronSelection_6/Max_grad/range/delta)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.275157: W tensorflow/c/c_api.cc:304] Operation '{name:'gradients_81/MaxNeuronSelection_6/Max_grad/mod' id:5035 op device:{requested: '', assigned: ''} def:{{{node gradients_81/MaxNeuronSelection_6/Max_grad/mod}} = FloorMod[T=DT_INT32, _class=[\"loc:@MaxNeuronSelection_6/Max\"], _has_manual_control_dependencies=true](gradients_81/MaxNeuronSelection_6/Max_grad/add, gradients_81/MaxNeuronSelection_6/Max_grad/Size)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.349380: W tensorflow/c/c_api.cc:304] Operation '{name:'gradients_81/MaxNeuronSelection_6/Max_grad/ones' id:5041 op device:{requested: '', assigned: ''} def:{{{node gradients_81/MaxNeuronSelection_6/Max_grad/ones}} = Fill[T=DT_INT32, _class=[\"loc:@MaxNeuronSelection_6/Max\"], _has_manual_control_dependencies=true, index_type=DT_INT32](gradients_81/MaxNeuronSelection_6/Max_grad/Shape_1, gradients_81/MaxNeuronSelection_6/Max_grad/ones/Const)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.426370: W tensorflow/c/c_api.cc:304] Operation '{name:'MaxNeuronSelection_6/Max/reduction_indices' id:4991 op device:{requested: '', assigned: ''} def:{{{node MaxNeuronSelection_6/Max/reduction_indices}} = Const[_has_manual_control_dependencies=true, dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: -1>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.503224: W tensorflow/c/c_api.cc:304] Operation '{name:'mul_12/x' id:5059 op device:{requested: '', assigned: ''} def:{{{node mul_12/x}} = Const[_has_manual_control_dependencies=true, dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1e-07>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.578666: W tensorflow/c/c_api.cc:304] Operation '{name:'Const_12' id:5056 op device:{requested: '', assigned: ''} def:{{{node Const_12}} = Const[_has_manual_control_dependencies=true, dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.739919: W tensorflow/c/c_api.cc:304] Operation '{name:'mul_13/x' id:5087 op device:{requested: '', assigned: ''} def:{{{node mul_13/x}} = Const[_has_manual_control_dependencies=true, dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1e-07>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-02-05 22:29:36.815350: W tensorflow/c/c_api.cc:304] Operation '{name:'Const_13' id:5084 op device:{requested: '', assigned: ''} def:{{{node Const_13}} = Const[_has_manual_control_dependencies=true, dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 0>]()}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fwd Packets/s', ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Bwd Packets/s', ' Min Packet Length', ' Fwd IAT Min', ' Fwd Header Length', ' Bwd IAT Min', ' Active Max', ' Bwd Header Length', ' Flow IAT Min', 'Total Length of Fwd Packets', ' Active Min', ' RST Flag Count', ' ECE Flag Count', ' Active Std', 'Active Mean', ' Subflow Fwd Bytes', ' Total Fwd Packets', ' Subflow Bwd Bytes', ' Total Backward Packets', ' Total Length of Bwd Packets', ' CWE Flag Count', 'Subflow Fwd Packets', ' Fwd URG Flags', ' act_data_pkt_fwd', ' Subflow Bwd Packets', 'Flow Bytes/s', ' Flow Packets/s', ' Bwd PSH Flags', ' Bwd URG Flags', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate')\n",
      "(1380.063720703125, 561.2511596679688, 402.34832763671875, 362.64154052734375, 272.8449401855469, 206.76412963867188, 112.88215637207031, 102.42752075195312, 76.74948120117188, 52.56433868408203, 33.0918083190918, 27.06095314025879, 24.385690689086914, 23.65891456604004, 22.806255340576172, 18.58475112915039, 15.588218688964844, 9.976822853088379, 3.201383113861084, 2.5176522731781006, 1.5887713432312012, 1.411143183708191, 0.9647161960601807, 0.8851308822631836, 0.7754836082458496, 0.7329273223876953, 0.34133732318878174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "CPU times: user 1.42 s, sys: 7.35 ms, total: 1.43 s\n",
      "Wall time: 1.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Fwd Packets/s',\n",
       " ' Fwd Packet Length Max',\n",
       " ' Fwd Packet Length Min',\n",
       " ' Bwd Packets/s',\n",
       " ' Min Packet Length',\n",
       " ' Fwd IAT Min',\n",
       " ' Fwd Header Length',\n",
       " ' Bwd IAT Min',\n",
       " ' Active Max',\n",
       " ' Bwd Header Length',\n",
       " ' Flow IAT Min',\n",
       " 'Total Length of Fwd Packets',\n",
       " ' Active Min',\n",
       " ' RST Flag Count',\n",
       " ' ECE Flag Count',\n",
       " ' Active Std',\n",
       " 'Active Mean',\n",
       " ' Subflow Fwd Bytes',\n",
       " ' Total Fwd Packets',\n",
       " ' Subflow Bwd Bytes',\n",
       " ' Total Backward Packets',\n",
       " ' Total Length of Bwd Packets',\n",
       " ' CWE Flag Count',\n",
       " 'Subflow Fwd Packets',\n",
       " ' Fwd URG Flags',\n",
       " ' act_data_pkt_fwd',\n",
       " ' Subflow Bwd Packets',\n",
       " 'Flow Bytes/s',\n",
       " ' Flow Packets/s',\n",
       " ' Bwd PSH Flags',\n",
       " ' Bwd URG Flags',\n",
       " 'Fwd Avg Bytes/Bulk',\n",
       " ' Fwd Avg Packets/Bulk',\n",
       " ' Fwd Avg Bulk Rate',\n",
       " ' Bwd Avg Bytes/Bulk',\n",
       " ' Bwd Avg Packets/Bulk',\n",
       " 'Bwd Avg Bulk Rate')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create an analyzer for the model\n",
    "analyzer = innvestigate.create_analyzer(\"lrp.z\", model)\n",
    "\n",
    "# Perform LRP analysis on the input data\n",
    "analysis = analyzer.analyze(X_test)\n",
    "\n",
    "# Perform LRP analysis on a certain number of samples\n",
    "# analysis = analyzer.analyze(X_test.sample(10000))\n",
    "\n",
    "#uncomment for single sample\n",
    "# analysis = analyzer.analyze(single_sample_df)\n",
    "\n",
    "\n",
    "names = X_test.columns\n",
    "scores = pd.DataFrame(analysis)\n",
    "scores_abs = scores.abs()\n",
    "\n",
    "# Calculate the sum of each column\n",
    "sum_of_columns = scores_abs.sum(axis=0)\n",
    "\n",
    "names = list(names)\n",
    "\n",
    "sum_of_columns = list(sum_of_columns)\n",
    "\n",
    "# Zip the two lists together\n",
    "combined = list(zip(names, sum_of_columns))\n",
    "\n",
    "# Sort the combined list in descending order based on the values from sum_of_columns\n",
    "sorted_combined = sorted(combined, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Unzip the sorted_combined list to separate names and sum_of_columns\n",
    "sorted_names, sorted_sum_of_columns = zip(*sorted_combined)\n",
    "\n",
    "print(sorted_names)\n",
    "print(sorted_sum_of_columns)\n",
    "\n",
    "sorted_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Generating Explainer\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        col_name  feature_importance_vals\n",
      "16                 Fwd Packets/s                 0.044661\n",
      "4          Fwd Packet Length Max                 0.016437\n",
      "18             Min Packet Length                 0.014087\n",
      "5          Fwd Packet Length Min                 0.008743\n",
      "9                    Fwd IAT Min                 0.008341\n",
      "17                 Bwd Packets/s                 0.007888\n",
      "10                   Bwd IAT Min                 0.005529\n",
      "35                    Active Max                 0.003400\n",
      "8                   Flow IAT Min                 0.002168\n",
      "36                    Active Min                 0.001126\n",
      "2    Total Length of Fwd Packets                 0.000884\n",
      "34                    Active Std                 0.000872\n",
      "33                   Active Mean                 0.000450\n",
      "29             Subflow Fwd Bytes                 0.000331\n",
      "20                CWE Flag Count                 0.000135\n",
      "12                 Fwd URG Flags                 0.000088\n",
      "14             Fwd Header Length                 0.000074\n",
      "0              Total Fwd Packets                 0.000044\n",
      "31             Subflow Bwd Bytes                 0.000043\n",
      "15             Bwd Header Length                 0.000032\n",
      "28           Subflow Fwd Packets                 0.000028\n",
      "1         Total Backward Packets                 0.000027\n",
      "3    Total Length of Bwd Packets                 0.000018\n",
      "32              act_data_pkt_fwd                 0.000017\n",
      "30           Subflow Bwd Packets                 0.000010\n",
      "27             Bwd Avg Bulk Rate                 0.000000\n",
      "7                 Flow Packets/s                 0.000000\n",
      "26          Bwd Avg Packets/Bulk                 0.000000\n",
      "25            Bwd Avg Bytes/Bulk                 0.000000\n",
      "24             Fwd Avg Bulk Rate                 0.000000\n",
      "11                 Bwd PSH Flags                 0.000000\n",
      "22            Fwd Avg Bytes/Bulk                 0.000000\n",
      "21                ECE Flag Count                 0.000000\n",
      "19                RST Flag Count                 0.000000\n",
      "6                   Flow Bytes/s                 0.000000\n",
      "13                 Bwd URG Flags                 0.000000\n",
      "23          Fwd Avg Packets/Bulk                 0.000000\n",
      "---------------------------------------------------------------------------------\n",
      "Trial_ =[\n",
      "'Fwd Packets/s',\n",
      "' Fwd Packet Length Max',\n",
      "' Min Packet Length',\n",
      "' Fwd Packet Length Min',\n",
      "' Fwd IAT Min',\n",
      "' Bwd Packets/s',\n",
      "' Bwd IAT Min',\n",
      "' Active Max',\n",
      "' Flow IAT Min',\n",
      "' Active Min',\n",
      "'Total Length of Fwd Packets',\n",
      "' Active Std',\n",
      "'Active Mean',\n",
      "' Subflow Fwd Bytes',\n",
      "' CWE Flag Count',\n",
      "' Fwd URG Flags',\n",
      "' Fwd Header Length',\n",
      "' Total Fwd Packets',\n",
      "' Subflow Bwd Bytes',\n",
      "' Bwd Header Length',\n",
      "'Subflow Fwd Packets',\n",
      "' Total Backward Packets',\n",
      "' Total Length of Bwd Packets',\n",
      "' act_data_pkt_fwd',\n",
      "' Subflow Bwd Packets',\n",
      "'Bwd Avg Bulk Rate',\n",
      "' Flow Packets/s',\n",
      "' Bwd Avg Packets/Bulk',\n",
      "' Bwd Avg Bytes/Bulk',\n",
      "' Fwd Avg Bulk Rate',\n",
      "' Bwd PSH Flags',\n",
      "'Fwd Avg Bytes/Bulk',\n",
      "' ECE Flag Count',\n",
      "' RST Flag Count',\n",
      "'Flow Bytes/s',\n",
      "' Bwd URG Flags',\n",
      "' Fwd Avg Packets/Bulk',\n",
      "---------------------------------------------------------------------------------\n",
      "CPU times: user 1min 28s, sys: 4.65 s, total: 1min 33s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(output_file_name, \"a\") as f:print('',file = f)\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Generating Explainer')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "samples = 2500\n",
    "\n",
    "# uncomment for single sample\n",
    "# samples = 1\n",
    "\n",
    "Label = label\n",
    "\n",
    "test = X_test\n",
    "train = X_train\n",
    "start_index = 0\n",
    "\n",
    "end_index = samples\n",
    "explainer = shap.DeepExplainer(model,train[start_index:end_index].values.astype('float'))\n",
    "shap_values = explainer.shap_values(test[start_index:end_index].values.astype('float'))\n",
    "\n",
    "vals= np.abs(shap_values).mean(1)\n",
    "feature_importance = pd.DataFrame(list(zip(train.columns, sum(vals))), columns=['col_name','feature_importance_vals'])\n",
    "feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)\n",
    "feature_importance.head()\n",
    "print(feature_importance.to_string())\n",
    "\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "# feature_importance_vals = 'feature_importance_vals'  # Replace with the name of the column you want to extract\n",
    "feature_val = feature_importance['feature_importance_vals'].tolist()\n",
    "\n",
    "# col_name = 'col_name'  # Replace with the name of the column you want to extract\n",
    "feature_name = feature_importance['col_name'].tolist()\n",
    "\n",
    "# Use zip to combine the two lists, sort based on list1, and then unzip them\n",
    "zipped_lists = list(zip(feature_name, feature_val))\n",
    "zipped_lists.sort(key=lambda x: x[1],reverse=True)\n",
    "\n",
    "# Convert the sorted result back into separate lists\n",
    "sorted_list1, sorted_list2 = [list(x) for x in zip(*zipped_lists)]\n",
    "\n",
    "for k in sorted_list1:\n",
    "  with open(output_file_name, \"a\") as f:print(\"df.pop('\",k,\"')\", sep='',file = f)\n",
    "with open(output_file_name, \"a\") as f:print(\"Trial_ =[\", file = f)\n",
    "print(\"Trial_ =[\")\n",
    "for k in sorted_list1:\n",
    "  with open(output_file_name, \"a\") as f:print(\"'\",k,\"',\", sep='', file = f)\n",
    "  print(\"'\",k,\"',\", sep='')\n",
    "with open(output_file_name, \"a\") as f:print(\"]\", file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
